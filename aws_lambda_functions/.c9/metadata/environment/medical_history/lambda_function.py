{"filter":false,"title":"lambda_function.py","tooltip":"/medical_history/lambda_function.py","undoManager":{"mark":100,"position":100,"stack":[[{"start":{"row":37,"column":49},"end":{"row":37,"column":51},"action":"remove","lines":["  "],"id":32},{"start":{"row":38,"column":57},"end":{"row":38,"column":59},"action":"remove","lines":["  "]}],[{"start":{"row":30,"column":0},"end":{"row":48,"column":0},"action":"remove","lines":["You are an expert insurance-policy assistant. Use ONLY the text in the CONTEXT to answer.","","**Rules:**","- **Coverage questions** (“Is X covered?”, “Does my plan pay for Y?”, etc.):","  1. **Answer:** start with “Yes” or “No” (capitalized), then a one-sentence explanation.","  2. **Evidence:** section title, clause number or page.","  3. **Next steps:** how to claim or apply.","- **Informational questions** (no yes/no needed):","  – Reply with one clear sentence summarizing the answer.","  – Optionally include an **Evidence** citation if it strengthens the response.","","### CONTEXT:","{context}","","### QUESTION:","{question}","","### REPLY:",""],"id":33},{"start":{"row":30,"column":0},"end":{"row":50,"column":0},"action":"insert","lines":["You are an expert insurance-policy assistant. Use ONLY the text in the CONTEXT to answer.","","-- INSTRUCTIONS --","1. If the user’s question is about whether something is covered (e.g. “Is X covered?”, “Does my plan pay for Y?”):","   • **Answer** must begin with “Yes” or “No” (capitalized), followed by one clear sentence.","   • **Evidence** must name the section title, clause number, or page.","   • **NextSteps** must explain how to claim or apply this (e.g. forms, deadlines).","","2. Otherwise (informational questions):","   • Reply with a single clear sentence as **Answer**.","   • You MAY include **Evidence** in parentheses at the end.","","-- OUTPUT FORMAT (JSON) --","For coverage questions:","```json","{","  \"Answer\": \"Yes – …\",","  \"Evidence\": \"Section 5.2 (Emergency Outpatient Treatment)\",","  \"NextSteps\": \"Submit form PA-1 with your X-ray invoice within 180 days.\"","}",""]}],[{"start":{"row":12,"column":12},"end":{"row":12,"column":45},"action":"remove","lines":["Llama-4-Maverick-17B-128E-Instruc"],"id":34}],[{"start":{"row":12,"column":12},"end":{"row":12,"column":13},"action":"remove","lines":["t"],"id":35}],[{"start":{"row":12,"column":12},"end":{"row":12,"column":41},"action":"insert","lines":["DeepSeek-R1-Distill-Llama-70B"],"id":36}],[{"start":{"row":58,"column":22},"end":{"row":58,"column":23},"action":"remove","lines":["3"],"id":37},{"start":{"row":58,"column":21},"end":{"row":58,"column":22},"action":"remove","lines":["."]}],[{"start":{"row":47,"column":17},"end":{"row":47,"column":59},"action":"remove","lines":["ction 5.2 (Emergency Outpatient Treatment)"],"id":38},{"start":{"row":47,"column":16},"end":{"row":47,"column":17},"action":"remove","lines":["e"]},{"start":{"row":47,"column":15},"end":{"row":47,"column":16},"action":"remove","lines":["S"]}],[{"start":{"row":47,"column":15},"end":{"row":47,"column":16},"action":"insert","lines":["."],"id":39},{"start":{"row":47,"column":16},"end":{"row":47,"column":17},"action":"insert","lines":["."]},{"start":{"row":47,"column":17},"end":{"row":47,"column":18},"action":"insert","lines":["."]}],[{"start":{"row":48,"column":17},"end":{"row":48,"column":73},"action":"remove","lines":["ubmit form PA-1 with your X-ray invoice within 180 days."],"id":40},{"start":{"row":48,"column":16},"end":{"row":48,"column":17},"action":"remove","lines":["S"]},{"start":{"row":48,"column":15},"end":{"row":48,"column":17},"action":"remove","lines":["\"\""]}],[{"start":{"row":48,"column":15},"end":{"row":48,"column":16},"action":"insert","lines":["\""],"id":41}],[{"start":{"row":48,"column":15},"end":{"row":48,"column":16},"action":"remove","lines":["\""],"id":42}],[{"start":{"row":48,"column":15},"end":{"row":48,"column":16},"action":"insert","lines":["\""],"id":43}],[{"start":{"row":48,"column":16},"end":{"row":48,"column":18},"action":"insert","lines":["\"\""],"id":44}],[{"start":{"row":48,"column":16},"end":{"row":48,"column":17},"action":"insert","lines":["."],"id":45},{"start":{"row":48,"column":17},"end":{"row":48,"column":18},"action":"insert","lines":["."]},{"start":{"row":48,"column":18},"end":{"row":48,"column":19},"action":"insert","lines":["."]}],[{"start":{"row":12,"column":12},"end":{"row":12,"column":40},"action":"remove","lines":["DeepSeek-R1-Distill-Llama-70"],"id":46}],[{"start":{"row":12,"column":12},"end":{"row":12,"column":13},"action":"remove","lines":["B"],"id":47}],[{"start":{"row":12,"column":12},"end":{"row":12,"column":39},"action":"insert","lines":["Meta-Llama-3.3-70B-Instruct"],"id":48}],[{"start":{"row":30,"column":0},"end":{"row":49,"column":1},"action":"remove","lines":["You are an expert insurance-policy assistant. Use ONLY the text in the CONTEXT to answer.","","-- INSTRUCTIONS --","1. If the user’s question is about whether something is covered (e.g. “Is X covered?”, “Does my plan pay for Y?”):","   • **Answer** must begin with “Yes” or “No” (capitalized), followed by one clear sentence.","   • **Evidence** must name the section title, clause number, or page.","   • **NextSteps** must explain how to claim or apply this (e.g. forms, deadlines).","","2. Otherwise (informational questions):","   • Reply with a single clear sentence as **Answer**.","   • You MAY include **Evidence** in parentheses at the end.","","-- OUTPUT FORMAT (JSON) --","For coverage questions:","```json","{","  \"Answer\": \"Yes – …\",","  \"Evidence\": \"...\",","  \"NextSteps\": \"...\"\"","}"],"id":49},{"start":{"row":30,"column":0},"end":{"row":48,"column":0},"action":"insert","lines":["You are an expert insurance-policy assistant. Use ONLY the text in the CONTEXT to answer.","","— If the user’s question is about whether something is covered (e.g. “Is X covered?”, “Does my plan pay for Y?”):","   • **Answer** must begin with “Yes” or “No” (capitalized) and be **exactly three short sentences** in total:  ","     1. The Yes/No conclusion.  ","     2. One brief evidence sentence naming the section title, clause number, or page.  ","     3. One brief next-step sentence explaining how to claim or apply (forms, deadlines, etc.).","","— Otherwise (informational questions):","   • Reply with **exactly three short sentences**.  ","   • You MAY include **Evidence** in parentheses at the end of any sentence.","","OUTPUT FORMAT (JSON) —","{","  \"answer\": \"Yes – …\",      // three short sentences","  \"confidence\": \"…\",","  \"nextSteps\": \"…\"          // optional; you can repeat sentence 3 here if you like","}",""]}],[{"start":{"row":44,"column":19},"end":{"row":44,"column":20},"action":"remove","lines":["…"],"id":50},{"start":{"row":44,"column":18},"end":{"row":44,"column":19},"action":"remove","lines":[" "]},{"start":{"row":44,"column":17},"end":{"row":44,"column":18},"action":"remove","lines":["–"]},{"start":{"row":44,"column":16},"end":{"row":44,"column":17},"action":"remove","lines":[" "]}],[{"start":{"row":45,"column":3},"end":{"row":45,"column":13},"action":"remove","lines":["confidence"],"id":51}],[{"start":{"row":45,"column":3},"end":{"row":45,"column":4},"action":"insert","lines":["r"],"id":52},{"start":{"row":45,"column":4},"end":{"row":45,"column":5},"action":"insert","lines":["e"]},{"start":{"row":45,"column":5},"end":{"row":45,"column":6},"action":"insert","lines":["a"]},{"start":{"row":45,"column":6},"end":{"row":45,"column":7},"action":"insert","lines":["s"]},{"start":{"row":45,"column":7},"end":{"row":45,"column":8},"action":"insert","lines":["o"]},{"start":{"row":45,"column":8},"end":{"row":45,"column":9},"action":"insert","lines":["n"]}],[{"start":{"row":45,"column":9},"end":{"row":45,"column":10},"action":"insert","lines":["-"],"id":53}],[{"start":{"row":45,"column":10},"end":{"row":45,"column":11},"action":"insert","lines":[" "],"id":54},{"start":{"row":45,"column":11},"end":{"row":45,"column":12},"action":"insert","lines":["w"]},{"start":{"row":45,"column":12},"end":{"row":45,"column":13},"action":"insert","lines":["y"]}],[{"start":{"row":45,"column":13},"end":{"row":45,"column":14},"action":"insert","lines":[" "],"id":55}],[{"start":{"row":45,"column":13},"end":{"row":45,"column":14},"action":"remove","lines":[" "],"id":56},{"start":{"row":45,"column":12},"end":{"row":45,"column":13},"action":"remove","lines":["y"]}],[{"start":{"row":45,"column":12},"end":{"row":45,"column":13},"action":"insert","lines":["h"],"id":57},{"start":{"row":45,"column":13},"end":{"row":45,"column":14},"action":"insert","lines":["y"]}],[{"start":{"row":45,"column":14},"end":{"row":45,"column":15},"action":"insert","lines":[" "],"id":58},{"start":{"row":45,"column":15},"end":{"row":45,"column":16},"action":"insert","lines":["i"]},{"start":{"row":45,"column":16},"end":{"row":45,"column":17},"action":"insert","lines":["t"]}],[{"start":{"row":45,"column":17},"end":{"row":45,"column":18},"action":"insert","lines":[" "],"id":59},{"start":{"row":45,"column":18},"end":{"row":45,"column":19},"action":"insert","lines":["i"]},{"start":{"row":45,"column":19},"end":{"row":45,"column":20},"action":"insert","lines":["s"]}],[{"start":{"row":45,"column":20},"end":{"row":45,"column":21},"action":"insert","lines":[" "],"id":60},{"start":{"row":45,"column":21},"end":{"row":45,"column":22},"action":"insert","lines":["a"]}],[{"start":{"row":45,"column":22},"end":{"row":45,"column":23},"action":"insert","lines":[" "],"id":61},{"start":{"row":45,"column":23},"end":{"row":45,"column":24},"action":"insert","lines":["y"]},{"start":{"row":45,"column":24},"end":{"row":45,"column":25},"action":"insert","lines":["e"]},{"start":{"row":45,"column":25},"end":{"row":45,"column":26},"action":"insert","lines":["s"]}],[{"start":{"row":45,"column":26},"end":{"row":45,"column":27},"action":"insert","lines":[" "],"id":62},{"start":{"row":45,"column":27},"end":{"row":45,"column":28},"action":"insert","lines":["o"]},{"start":{"row":45,"column":28},"end":{"row":45,"column":29},"action":"insert","lines":["r"]}],[{"start":{"row":45,"column":29},"end":{"row":45,"column":30},"action":"insert","lines":[" "],"id":63},{"start":{"row":45,"column":30},"end":{"row":45,"column":31},"action":"insert","lines":["n"]},{"start":{"row":45,"column":31},"end":{"row":45,"column":32},"action":"insert","lines":["o"]}],[{"start":{"row":45,"column":31},"end":{"row":45,"column":32},"action":"remove","lines":["o"],"id":64},{"start":{"row":45,"column":30},"end":{"row":45,"column":31},"action":"remove","lines":["n"]},{"start":{"row":45,"column":29},"end":{"row":45,"column":30},"action":"remove","lines":[" "]},{"start":{"row":45,"column":28},"end":{"row":45,"column":29},"action":"remove","lines":["r"]},{"start":{"row":45,"column":27},"end":{"row":45,"column":28},"action":"remove","lines":["o"]},{"start":{"row":45,"column":26},"end":{"row":45,"column":27},"action":"remove","lines":[" "]},{"start":{"row":45,"column":25},"end":{"row":45,"column":26},"action":"remove","lines":["s"]},{"start":{"row":45,"column":24},"end":{"row":45,"column":25},"action":"remove","lines":["e"]},{"start":{"row":45,"column":23},"end":{"row":45,"column":24},"action":"remove","lines":["y"]},{"start":{"row":45,"column":22},"end":{"row":45,"column":23},"action":"remove","lines":[" "]},{"start":{"row":45,"column":21},"end":{"row":45,"column":22},"action":"remove","lines":["a"]},{"start":{"row":45,"column":20},"end":{"row":45,"column":21},"action":"remove","lines":[" "]},{"start":{"row":45,"column":19},"end":{"row":45,"column":20},"action":"remove","lines":["s"]},{"start":{"row":45,"column":18},"end":{"row":45,"column":19},"action":"remove","lines":["i"]},{"start":{"row":45,"column":17},"end":{"row":45,"column":18},"action":"remove","lines":[" "]},{"start":{"row":45,"column":16},"end":{"row":45,"column":17},"action":"remove","lines":["t"]},{"start":{"row":45,"column":15},"end":{"row":45,"column":16},"action":"remove","lines":["i"]},{"start":{"row":45,"column":14},"end":{"row":45,"column":15},"action":"remove","lines":[" "]},{"start":{"row":45,"column":13},"end":{"row":45,"column":14},"action":"remove","lines":["y"]},{"start":{"row":45,"column":12},"end":{"row":45,"column":13},"action":"remove","lines":["h"]},{"start":{"row":45,"column":11},"end":{"row":45,"column":12},"action":"remove","lines":["w"]},{"start":{"row":45,"column":10},"end":{"row":45,"column":11},"action":"remove","lines":[" "]},{"start":{"row":45,"column":9},"end":{"row":45,"column":10},"action":"remove","lines":["-"]}],[{"start":{"row":46,"column":0},"end":{"row":46,"column":83},"action":"remove","lines":["  \"nextSteps\": \"…\"          // optional; you can repeat sentence 3 here if you like"],"id":65}],[{"start":{"row":36,"column":95},"end":{"row":37,"column":0},"action":"insert","lines":["",""],"id":66},{"start":{"row":37,"column":0},"end":{"row":37,"column":5},"action":"insert","lines":["     "]},{"start":{"row":37,"column":5},"end":{"row":37,"column":6},"action":"insert","lines":["4"]},{"start":{"row":37,"column":6},"end":{"row":37,"column":7},"action":"insert","lines":["."]}],[{"start":{"row":37,"column":7},"end":{"row":37,"column":8},"action":"insert","lines":[" "],"id":67},{"start":{"row":37,"column":8},"end":{"row":37,"column":9},"action":"insert","lines":["G"]},{"start":{"row":37,"column":9},"end":{"row":37,"column":10},"action":"insert","lines":["i"]},{"start":{"row":37,"column":10},"end":{"row":37,"column":11},"action":"insert","lines":["v"]},{"start":{"row":37,"column":11},"end":{"row":37,"column":12},"action":"insert","lines":["e"]}],[{"start":{"row":37,"column":12},"end":{"row":37,"column":13},"action":"insert","lines":[" "],"id":68},{"start":{"row":37,"column":13},"end":{"row":37,"column":14},"action":"insert","lines":["t"]},{"start":{"row":37,"column":14},"end":{"row":37,"column":15},"action":"insert","lines":["h"]},{"start":{"row":37,"column":15},"end":{"row":37,"column":16},"action":"insert","lines":["e"]}],[{"start":{"row":37,"column":16},"end":{"row":37,"column":17},"action":"insert","lines":[" "],"id":69},{"start":{"row":37,"column":17},"end":{"row":37,"column":18},"action":"insert","lines":["r"]},{"start":{"row":37,"column":18},"end":{"row":37,"column":19},"action":"insert","lines":["e"]},{"start":{"row":37,"column":19},"end":{"row":37,"column":20},"action":"insert","lines":["a"]},{"start":{"row":37,"column":20},"end":{"row":37,"column":21},"action":"insert","lines":["s"]},{"start":{"row":37,"column":21},"end":{"row":37,"column":22},"action":"insert","lines":["o"]},{"start":{"row":37,"column":22},"end":{"row":37,"column":23},"action":"insert","lines":["n"]}],[{"start":{"row":37,"column":23},"end":{"row":37,"column":24},"action":"insert","lines":[" "],"id":70},{"start":{"row":37,"column":24},"end":{"row":37,"column":25},"action":"insert","lines":["f"]},{"start":{"row":37,"column":25},"end":{"row":37,"column":26},"action":"insert","lines":["o"]},{"start":{"row":37,"column":26},"end":{"row":37,"column":27},"action":"insert","lines":["r"]}],[{"start":{"row":37,"column":27},"end":{"row":37,"column":28},"action":"insert","lines":[" "],"id":71},{"start":{"row":37,"column":28},"end":{"row":37,"column":29},"action":"insert","lines":["y"]},{"start":{"row":37,"column":29},"end":{"row":37,"column":30},"action":"insert","lines":["e"]},{"start":{"row":37,"column":30},"end":{"row":37,"column":31},"action":"insert","lines":["s"]}],[{"start":{"row":37,"column":31},"end":{"row":37,"column":32},"action":"insert","lines":[" "],"id":72},{"start":{"row":37,"column":32},"end":{"row":37,"column":33},"action":"insert","lines":["o"]},{"start":{"row":37,"column":33},"end":{"row":37,"column":34},"action":"insert","lines":["r"]}],[{"start":{"row":37,"column":34},"end":{"row":37,"column":35},"action":"insert","lines":[" "],"id":73},{"start":{"row":37,"column":35},"end":{"row":37,"column":36},"action":"insert","lines":["n"]},{"start":{"row":37,"column":36},"end":{"row":37,"column":37},"action":"insert","lines":["o"]}],[{"start":{"row":37,"column":37},"end":{"row":37,"column":38},"action":"insert","lines":[" "],"id":74},{"start":{"row":37,"column":38},"end":{"row":37,"column":39},"action":"insert","lines":["i"]},{"start":{"row":37,"column":39},"end":{"row":37,"column":40},"action":"insert","lines":["n"]}],[{"start":{"row":37,"column":40},"end":{"row":37,"column":41},"action":"insert","lines":[" "],"id":75},{"start":{"row":37,"column":41},"end":{"row":37,"column":42},"action":"insert","lines":["t"]},{"start":{"row":37,"column":42},"end":{"row":37,"column":43},"action":"insert","lines":["h"]},{"start":{"row":37,"column":43},"end":{"row":37,"column":44},"action":"insert","lines":["e"]}],[{"start":{"row":37,"column":44},"end":{"row":37,"column":45},"action":"insert","lines":[" "],"id":76},{"start":{"row":37,"column":45},"end":{"row":37,"column":46},"action":"insert","lines":["r"]},{"start":{"row":37,"column":46},"end":{"row":37,"column":47},"action":"insert","lines":["e"]},{"start":{"row":37,"column":47},"end":{"row":37,"column":48},"action":"insert","lines":["a"]},{"start":{"row":37,"column":48},"end":{"row":37,"column":49},"action":"insert","lines":["s"]},{"start":{"row":37,"column":49},"end":{"row":37,"column":50},"action":"insert","lines":["o"]},{"start":{"row":37,"column":50},"end":{"row":37,"column":51},"action":"insert","lines":["n"]}],[{"start":{"row":37,"column":51},"end":{"row":37,"column":52},"action":"insert","lines":[" "],"id":77},{"start":{"row":37,"column":52},"end":{"row":37,"column":53},"action":"insert","lines":["s"]},{"start":{"row":37,"column":53},"end":{"row":37,"column":54},"action":"insert","lines":["e"]}],[{"start":{"row":37,"column":54},"end":{"row":37,"column":55},"action":"insert","lines":["c"],"id":78},{"start":{"row":37,"column":55},"end":{"row":37,"column":56},"action":"insert","lines":["t"]},{"start":{"row":37,"column":56},"end":{"row":37,"column":57},"action":"insert","lines":["i"]},{"start":{"row":37,"column":57},"end":{"row":37,"column":58},"action":"insert","lines":["o"]},{"start":{"row":37,"column":58},"end":{"row":37,"column":59},"action":"insert","lines":["n"]}],[{"start":{"row":33,"column":110},"end":{"row":33,"column":112},"action":"remove","lines":["  "],"id":79},{"start":{"row":34,"column":30},"end":{"row":34,"column":32},"action":"remove","lines":["  "]},{"start":{"row":35,"column":85},"end":{"row":35,"column":87},"action":"remove","lines":["  "]},{"start":{"row":40,"column":50},"end":{"row":40,"column":52},"action":"remove","lines":["  "]}],[{"start":{"row":31,"column":0},"end":{"row":126,"column":5},"action":"insert","lines":["s3      = boto3.client(\"s3\")","client  = OpenAI(api_key=SAMBANOVA_API_KEY, base_url=SAMBANOVA_API_BASE)","","# ─────────────────────────────────────────","# ► Helper functions","# ─────────────────────────────────────────","def list_txt_files(bucket: str) -> list[str]:","    \"\"\"Return all *.txt keys in the given bucket (paginates if needed).\"\"\"","    paginator = s3.get_paginator(\"list_objects_v2\")","    keys: list[str] = []","    for page in paginator.paginate(Bucket=bucket):","        keys.extend(k[\"Key\"] for k in page.get(\"Contents\", []) if k[\"Key\"].endswith(\".txt\"))","    return keys","","","def read_txt(bucket: str, key: str) -> str:","    \"\"\"Read a text object from S3 and decode to UTF-8.\"\"\"","    obj = s3.get_object(Bucket=bucket, Key=key)","    return obj[\"Body\"].read().decode(\"utf-8\")","","","def build_prompt(context: str, question: str) -> str:","    \"\"\"Create the strict three-sentence insurance Q&A prompt.\"\"\"","    return f\"\"\"","You are an expert insurance-policy assistant. Use **ONLY** the text in the CONTEXT to answer.","","────────────────────────────────","RULES","1. Reply with valid JSON containing a single key \"answer\".","2. \"answer\" must be **exactly three short sentences** (≈ ≤20 words each):","   • Sentence 1 – Begin with **Yes** or **No** and state the conclusion.  ","   • Sentence 2 – Cite a single piece of evidence (section title, clause, or page).  ","   • Sentence 3 – Give one next-step (how to claim, deadline, or required form).","3. Output **nothing** outside that JSON object.","","────────────────────────────────","CONTEXT","{context}","","────────────────────────────────","QUESTION","{question}","","Return only the JSON object described in rule 1.","\"\"\".strip()","","","def query_sambanova(prompt: str) -> str:","    \"\"\"Send the prompt to SambaNova and return the raw assistant message (JSON string).\"\"\"","    completion = client.chat.completions.create(","        model=MODEL_ID,","        messages=[{\"role\": \"user\", \"content\": prompt}],","        temperature=0,","        top_p=0.9,","    )","    return completion.choices[0].message.content","","","# ─────────────────────────────────────────","# ► Lambda entry-point","# ─────────────────────────────────────────","def lambda_handler(event, context):","    # 1️⃣ Parse body (works for API Gateway proxy or direct test invoke)","    try:","        body = event.get(\"body\", event)           # fallback to direct-style event","        if isinstance(body, str):","            body = json.loads(body)","        question = body[\"question\"]               # KeyError → handled by except","    except Exception as exc:","        return {","            \"statusCode\": 400,","            \"body\": json.dumps(f\"Invalid request structure: {exc}\")","        }","","    # 2️⃣ Aggregate all parsed PDF text into one CONTEXT string","    combined_text = \"\"","    for key in list_txt_files(PARSED_BUCKET):","        try:","            combined_text += f\"\\n\\n--- {key} ---\\n\\n{read_txt(PARSED_BUCKET, key)}\"","        except Exception as exc:","            combined_text += f\"\\n\\n--- Error reading {key}: {exc} ---\\n\\n\"","","    # 3️⃣ Build prompt, query LLM","    prompt       = build_prompt(combined_text, question)","    answer_json  = query_sambanova(prompt)        # already JSON per our prompt","","    # 4️⃣ Return straight through (CORS-friendly headers for API Gateway)","    return {","        \"statusCode\": 200,","        \"headers\": {","            \"Access-Control-Allow-Origin\":  \"*\",","            \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",","            \"Access-Control-Allow-Headers\": \"Content-Type\",","        },","        \"body\": answer_json","    }"],"id":80}],[{"start":{"row":78,"column":40},"end":{"row":173,"column":5},"action":"insert","lines":["s3      = boto3.client(\"s3\")","client  = OpenAI(api_key=SAMBANOVA_API_KEY, base_url=SAMBANOVA_API_BASE)","","# ─────────────────────────────────────────","# ► Helper functions","# ─────────────────────────────────────────","def list_txt_files(bucket: str) -> list[str]:","    \"\"\"Return all *.txt keys in the given bucket (paginates if needed).\"\"\"","    paginator = s3.get_paginator(\"list_objects_v2\")","    keys: list[str] = []","    for page in paginator.paginate(Bucket=bucket):","        keys.extend(k[\"Key\"] for k in page.get(\"Contents\", []) if k[\"Key\"].endswith(\".txt\"))","    return keys","","","def read_txt(bucket: str, key: str) -> str:","    \"\"\"Read a text object from S3 and decode to UTF-8.\"\"\"","    obj = s3.get_object(Bucket=bucket, Key=key)","    return obj[\"Body\"].read().decode(\"utf-8\")","","","def build_prompt(context: str, question: str) -> str:","    \"\"\"Create the strict three-sentence insurance Q&A prompt.\"\"\"","    return f\"\"\"","You are an expert insurance-policy assistant. Use **ONLY** the text in the CONTEXT to answer.","","────────────────────────────────","RULES","1. Reply with valid JSON containing a single key \"answer\".","2. \"answer\" must be **exactly three short sentences** (≈ ≤20 words each):","   • Sentence 1 – Begin with **Yes** or **No** and state the conclusion.  ","   • Sentence 2 – Cite a single piece of evidence (section title, clause, or page).  ","   • Sentence 3 – Give one next-step (how to claim, deadline, or required form).","3. Output **nothing** outside that JSON object.","","────────────────────────────────","CONTEXT","{context}","","────────────────────────────────","QUESTION","{question}","","Return only the JSON object described in rule 1.","\"\"\".strip()","","","def query_sambanova(prompt: str) -> str:","    \"\"\"Send the prompt to SambaNova and return the raw assistant message (JSON string).\"\"\"","    completion = client.chat.completions.create(","        model=MODEL_ID,","        messages=[{\"role\": \"user\", \"content\": prompt}],","        temperature=0,","        top_p=0.9,","    )","    return completion.choices[0].message.content","","","# ─────────────────────────────────────────","# ► Lambda entry-point","# ─────────────────────────────────────────","def lambda_handler(event, context):","    # 1️⃣ Parse body (works for API Gateway proxy or direct test invoke)","    try:","        body = event.get(\"body\", event)           # fallback to direct-style event","        if isinstance(body, str):","            body = json.loads(body)","        question = body[\"question\"]               # KeyError → handled by except","    except Exception as exc:","        return {","            \"statusCode\": 400,","            \"body\": json.dumps(f\"Invalid request structure: {exc}\")","        }","","    # 2️⃣ Aggregate all parsed PDF text into one CONTEXT string","    combined_text = \"\"","    for key in list_txt_files(PARSED_BUCKET):","        try:","            combined_text += f\"\\n\\n--- {key} ---\\n\\n{read_txt(PARSED_BUCKET, key)}\"","        except Exception as exc:","            combined_text += f\"\\n\\n--- Error reading {key}: {exc} ---\\n\\n\"","","    # 3️⃣ Build prompt, query LLM","    prompt       = build_prompt(combined_text, question)","    answer_json  = query_sambanova(prompt)        # already JSON per our prompt","","    # 4️⃣ Return straight through (CORS-friendly headers for API Gateway)","    return {","        \"statusCode\": 200,","        \"headers\": {","            \"Access-Control-Allow-Origin\":  \"*\",","            \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",","            \"Access-Control-Allow-Headers\": \"Content-Type\",","        },","        \"body\": answer_json","    }"],"id":81}],[{"start":{"row":0,"column":0},"end":{"row":296,"column":0},"action":"remove","lines":["import boto3","import json","import os","from openai import OpenAI","","# Initialize S3 client","s3 = boto3.client(\"s3\")","","# Your bucket with pre-parsed .txt files from PDFs","PARSED_BUCKET = \"elroy-and-co-insurance-docs-parsed\"","","# SambaNova config","MODEL_ID = \"Meta-Llama-3.3-70B-Instruct\"","SAMBANOVA_API_BASE = \"https://api.sambanova.ai/v1\"","","client = OpenAI(","    api_key=\"d830ceb2-cd0a-464b-b6b0-82a5f5710746\",","    base_url=SAMBANOVA_API_BASE,",")","","def list_txt_files(bucket):","    response = s3.list_objects_v2(Bucket=bucket)","    return [obj[\"Key\"] for obj in response.get(\"Contents\", []) if obj[\"Key\"].endswith(\".txt\")]","","def read_txt(bucket, key):","    response = s3.get_object(Bucket=bucket, Key=key)","    return response[\"Body\"].read().decode(\"utf-8\")","","def build_prompt(context, question):","    return f\"\"\"","You are an expert insurance-policy assistant. Use ONLY the text in the CONTEXT to answer.","s3      = boto3.client(\"s3\")","client  = OpenAI(api_key=SAMBANOVA_API_KEY, base_url=SAMBANOVA_API_BASE)","","# ─────────────────────────────────────────","# ► Helper functions","# ─────────────────────────────────────────","def list_txt_files(bucket: str) -> list[str]:","    \"\"\"Return all *.txt keys in the given bucket (paginates if needed).\"\"\"","    paginator = s3.get_paginator(\"list_objects_v2\")","    keys: list[str] = []","    for page in paginator.paginate(Bucket=bucket):","        keys.extend(k[\"Key\"] for k in page.get(\"Contents\", []) if k[\"Key\"].endswith(\".txt\"))","    return keys","","","def read_txt(bucket: str, key: str) -> str:","    \"\"\"Read a text object from S3 and decode to UTF-8.\"\"\"","    obj = s3.get_object(Bucket=bucket, Key=key)","    return obj[\"Body\"].read().decode(\"utf-8\")","","","def build_prompt(context: str, question: str) -> str:","    \"\"\"Create the strict three-sentence insurance Q&A prompt.\"\"\"","    return f\"\"\"","You are an expert insurance-policy assistant. Use **ONLY** the text in the CONTEXT to answer.","","────────────────────────────────","RULES","1. Reply with valid JSON containing a single key \"answer\".","2. \"answer\" must be **exactly three short sentences** (≈ ≤20 words each):","   • Sentence 1 – Begin with **Yes** or **No** and state the conclusion.  ","   • Sentence 2 – Cite a single piece of evidence (section title, clause, or page).  ","   • Sentence 3 – Give one next-step (how to claim, deadline, or required form).","3. Output **nothing** outside that JSON object.","","────────────────────────────────","CONTEXT","{context}","","────────────────────────────────","QUESTION","{question}","","Return only the JSON object described in rule 1.","\"\"\".strip()","","","def query_sambanova(prompt: str) -> str:s3      = boto3.client(\"s3\")","client  = OpenAI(api_key=SAMBANOVA_API_KEY, base_url=SAMBANOVA_API_BASE)","","# ─────────────────────────────────────────","# ► Helper functions","# ─────────────────────────────────────────","def list_txt_files(bucket: str) -> list[str]:","    \"\"\"Return all *.txt keys in the given bucket (paginates if needed).\"\"\"","    paginator = s3.get_paginator(\"list_objects_v2\")","    keys: list[str] = []","    for page in paginator.paginate(Bucket=bucket):","        keys.extend(k[\"Key\"] for k in page.get(\"Contents\", []) if k[\"Key\"].endswith(\".txt\"))","    return keys","","","def read_txt(bucket: str, key: str) -> str:","    \"\"\"Read a text object from S3 and decode to UTF-8.\"\"\"","    obj = s3.get_object(Bucket=bucket, Key=key)","    return obj[\"Body\"].read().decode(\"utf-8\")","","","def build_prompt(context: str, question: str) -> str:","    \"\"\"Create the strict three-sentence insurance Q&A prompt.\"\"\"","    return f\"\"\"","You are an expert insurance-policy assistant. Use **ONLY** the text in the CONTEXT to answer.","","────────────────────────────────","RULES","1. Reply with valid JSON containing a single key \"answer\".","2. \"answer\" must be **exactly three short sentences** (≈ ≤20 words each):","   • Sentence 1 – Begin with **Yes** or **No** and state the conclusion.  ","   • Sentence 2 – Cite a single piece of evidence (section title, clause, or page).  ","   • Sentence 3 – Give one next-step (how to claim, deadline, or required form).","3. Output **nothing** outside that JSON object.","","────────────────────────────────","CONTEXT","{context}","","────────────────────────────────","QUESTION","{question}","","Return only the JSON object described in rule 1.","\"\"\".strip()","","","def query_sambanova(prompt: str) -> str:","    \"\"\"Send the prompt to SambaNova and return the raw assistant message (JSON string).\"\"\"","    completion = client.chat.completions.create(","        model=MODEL_ID,","        messages=[{\"role\": \"user\", \"content\": prompt}],","        temperature=0,","        top_p=0.9,","    )","    return completion.choices[0].message.content","","","# ─────────────────────────────────────────","# ► Lambda entry-point","# ─────────────────────────────────────────","def lambda_handler(event, context):","    # 1️⃣ Parse body (works for API Gateway proxy or direct test invoke)","    try:","        body = event.get(\"body\", event)           # fallback to direct-style event","        if isinstance(body, str):","            body = json.loads(body)","        question = body[\"question\"]               # KeyError → handled by except","    except Exception as exc:","        return {","            \"statusCode\": 400,","            \"body\": json.dumps(f\"Invalid request structure: {exc}\")","        }","","    # 2️⃣ Aggregate all parsed PDF text into one CONTEXT string","    combined_text = \"\"","    for key in list_txt_files(PARSED_BUCKET):","        try:","            combined_text += f\"\\n\\n--- {key} ---\\n\\n{read_txt(PARSED_BUCKET, key)}\"","        except Exception as exc:","            combined_text += f\"\\n\\n--- Error reading {key}: {exc} ---\\n\\n\"","","    # 3️⃣ Build prompt, query LLM","    prompt       = build_prompt(combined_text, question)","    answer_json  = query_sambanova(prompt)        # already JSON per our prompt","","    # 4️⃣ Return straight through (CORS-friendly headers for API Gateway)","    return {","        \"statusCode\": 200,","        \"headers\": {","            \"Access-Control-Allow-Origin\":  \"*\",","            \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",","            \"Access-Control-Allow-Headers\": \"Content-Type\",","        },","        \"body\": answer_json","    }","    \"\"\"Send the prompt to SambaNova and return the raw assistant message (JSON string).\"\"\"","    completion = client.chat.completions.create(","        model=MODEL_ID,","        messages=[{\"role\": \"user\", \"content\": prompt}],","        temperature=0,","        top_p=0.9,","    )","    return completion.choices[0].message.content","","","# ─────────────────────────────────────────","# ► Lambda entry-point","# ─────────────────────────────────────────","def lambda_handler(event, context):","    # 1️⃣ Parse body (works for API Gateway proxy or direct test invoke)","    try:","        body = event.get(\"body\", event)           # fallback to direct-style event","        if isinstance(body, str):","            body = json.loads(body)","        question = body[\"question\"]               # KeyError → handled by except","    except Exception as exc:","        return {","            \"statusCode\": 400,","            \"body\": json.dumps(f\"Invalid request structure: {exc}\")","        }","","    # 2️⃣ Aggregate all parsed PDF text into one CONTEXT string","    combined_text = \"\"","    for key in list_txt_files(PARSED_BUCKET):","        try:","            combined_text += f\"\\n\\n--- {key} ---\\n\\n{read_txt(PARSED_BUCKET, key)}\"","        except Exception as exc:","            combined_text += f\"\\n\\n--- Error reading {key}: {exc} ---\\n\\n\"","","    # 3️⃣ Build prompt, query LLM","    prompt       = build_prompt(combined_text, question)","    answer_json  = query_sambanova(prompt)        # already JSON per our prompt","","    # 4️⃣ Return straight through (CORS-friendly headers for API Gateway)","    return {","        \"statusCode\": 200,","        \"headers\": {","            \"Access-Control-Allow-Origin\":  \"*\",","            \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",","            \"Access-Control-Allow-Headers\": \"Content-Type\",","        },","        \"body\": answer_json","    }","— If the user’s question is about whether something is covered (e.g. “Is X covered?”, “Does my plan pay for Y?”):","   • **Answer** must begin with “Yes” or “No” (capitalized) and be **exactly three short sentences** in total:","     1. The Yes/No conclusion.","     2. One brief evidence sentence naming the section title, clause number, or page.","     3. One brief next-step sentence explaining how to claim or apply (forms, deadlines, etc.).","     4. Give the reason for yes or no in the reason section","","— Otherwise (informational questions):","   • Reply with **exactly three short sentences**.","   • You MAY include **Evidence** in parentheses at the end of any sentence.","","OUTPUT FORMAT (JSON) —","{","  \"answer\": \"Yes\",      // three short sentences","  \"reason\": \"…\",","","}","","","","\"\"\"","","def query_sambanova(prompt):","    response = client.chat.completions.create(","        model=MODEL_ID,","        messages=[{\"role\": \"user\", \"content\": prompt}],","        temperature=0,","        top_p=0.9","    )","    return response.choices[0].message.content","","def lambda_handler(event, context):","    try:","        body = event.get(\"body\")","        if isinstance(body, str):","            body = json.loads(body)","        question = body.get(\"question\")","    except Exception as e:","        return {","            \"statusCode\": 400,","            \"body\": json.dumps(\"Invalid request structure.\")","        }","","    if not question:","        return {","            \"statusCode\": 400,","            \"body\": json.dumps(\"Missing 'question' in request.\")","        }","","    # Read and merge context","    combined_text = \"\"","    for key in list_txt_files(PARSED_BUCKET):","        try:","            text = read_txt(PARSED_BUCKET, key)","            combined_text += f\"\\n\\n--- {key} ---\\n\\n{text}\"","        except Exception as e:","            combined_text += f\"\\n\\n--- Error reading {key}: {str(e)} ---\\n\\n\"","","    # Build prompt and query LLM","    prompt = build_prompt(combined_text, question)","    answer = query_sambanova(prompt)","","    return {","        \"statusCode\": 200,","        \"headers\": {","            \"Access-Control-Allow-Origin\": \"*\",","            \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",","            \"Access-Control-Allow-Headers\": \"Content-Type\"","        },","        \"body\": json.dumps({","            \"question\": question,","            \"answer\": answer","        })","    }",""],"id":82},{"start":{"row":0,"column":0},"end":{"row":95,"column":5},"action":"insert","lines":["s3      = boto3.client(\"s3\")","client  = OpenAI(api_key=SAMBANOVA_API_KEY, base_url=SAMBANOVA_API_BASE)","","# ─────────────────────────────────────────","# ► Helper functions","# ─────────────────────────────────────────","def list_txt_files(bucket: str) -> list[str]:","    \"\"\"Return all *.txt keys in the given bucket (paginates if needed).\"\"\"","    paginator = s3.get_paginator(\"list_objects_v2\")","    keys: list[str] = []","    for page in paginator.paginate(Bucket=bucket):","        keys.extend(k[\"Key\"] for k in page.get(\"Contents\", []) if k[\"Key\"].endswith(\".txt\"))","    return keys","","","def read_txt(bucket: str, key: str) -> str:","    \"\"\"Read a text object from S3 and decode to UTF-8.\"\"\"","    obj = s3.get_object(Bucket=bucket, Key=key)","    return obj[\"Body\"].read().decode(\"utf-8\")","","","def build_prompt(context: str, question: str) -> str:","    \"\"\"Create the strict three-sentence insurance Q&A prompt.\"\"\"","    return f\"\"\"","You are an expert insurance-policy assistant. Use **ONLY** the text in the CONTEXT to answer.","","────────────────────────────────","RULES","1. Reply with valid JSON containing a single key \"answer\".","2. \"answer\" must be **exactly three short sentences** (≈ ≤20 words each):","   • Sentence 1 – Begin with **Yes** or **No** and state the conclusion.  ","   • Sentence 2 – Cite a single piece of evidence (section title, clause, or page).  ","   • Sentence 3 – Give one next-step (how to claim, deadline, or required form).","3. Output **nothing** outside that JSON object.","","────────────────────────────────","CONTEXT","{context}","","────────────────────────────────","QUESTION","{question}","","Return only the JSON object described in rule 1.","\"\"\".strip()","","","def query_sambanova(prompt: str) -> str:","    \"\"\"Send the prompt to SambaNova and return the raw assistant message (JSON string).\"\"\"","    completion = client.chat.completions.create(","        model=MODEL_ID,","        messages=[{\"role\": \"user\", \"content\": prompt}],","        temperature=0,","        top_p=0.9,","    )","    return completion.choices[0].message.content","","","# ─────────────────────────────────────────","# ► Lambda entry-point","# ─────────────────────────────────────────","def lambda_handler(event, context):","    # 1️⃣ Parse body (works for API Gateway proxy or direct test invoke)","    try:","        body = event.get(\"body\", event)           # fallback to direct-style event","        if isinstance(body, str):","            body = json.loads(body)","        question = body[\"question\"]               # KeyError → handled by except","    except Exception as exc:","        return {","            \"statusCode\": 400,","            \"body\": json.dumps(f\"Invalid request structure: {exc}\")","        }","","    # 2️⃣ Aggregate all parsed PDF text into one CONTEXT string","    combined_text = \"\"","    for key in list_txt_files(PARSED_BUCKET):","        try:","            combined_text += f\"\\n\\n--- {key} ---\\n\\n{read_txt(PARSED_BUCKET, key)}\"","        except Exception as exc:","            combined_text += f\"\\n\\n--- Error reading {key}: {exc} ---\\n\\n\"","","    # 3️⃣ Build prompt, query LLM","    prompt       = build_prompt(combined_text, question)","    answer_json  = query_sambanova(prompt)        # already JSON per our prompt","","    # 4️⃣ Return straight through (CORS-friendly headers for API Gateway)","    return {","        \"statusCode\": 200,","        \"headers\": {","            \"Access-Control-Allow-Origin\":  \"*\",","            \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",","            \"Access-Control-Allow-Headers\": \"Content-Type\",","        },","        \"body\": answer_json","    }"]}],[{"start":{"row":1,"column":25},"end":{"row":1,"column":42},"action":"remove","lines":["SAMBANOVA_API_KEY"],"id":83},{"start":{"row":1,"column":25},"end":{"row":1,"column":26},"action":"insert","lines":["\""]}],[{"start":{"row":1,"column":26},"end":{"row":1,"column":62},"action":"insert","lines":["d830ceb2-cd0a-464b-b6b0-82a5f5710746"],"id":84}],[{"start":{"row":1,"column":62},"end":{"row":1,"column":63},"action":"insert","lines":["\""],"id":85}],[{"start":{"row":30,"column":72},"end":{"row":30,"column":74},"action":"remove","lines":["  "],"id":86},{"start":{"row":31,"column":83},"end":{"row":31,"column":85},"action":"remove","lines":["  "]}],[{"start":{"row":32,"column":0},"end":{"row":32,"column":80},"action":"remove","lines":["   • Sentence 3 – Give one next-step (how to claim, deadline, or required form)."],"id":89},{"start":{"row":31,"column":83},"end":{"row":32,"column":0},"action":"remove","lines":["",""]}],[{"start":{"row":0,"column":0},"end":{"row":94,"column":5},"action":"remove","lines":["s3      = boto3.client(\"s3\")","client  = OpenAI(api_key=\"d830ceb2-cd0a-464b-b6b0-82a5f5710746\", base_url=SAMBANOVA_API_BASE)","","# ─────────────────────────────────────────","# ► Helper functions","# ─────────────────────────────────────────","def list_txt_files(bucket: str) -> list[str]:","    \"\"\"Return all *.txt keys in the given bucket (paginates if needed).\"\"\"","    paginator = s3.get_paginator(\"list_objects_v2\")","    keys: list[str] = []","    for page in paginator.paginate(Bucket=bucket):","        keys.extend(k[\"Key\"] for k in page.get(\"Contents\", []) if k[\"Key\"].endswith(\".txt\"))","    return keys","","","def read_txt(bucket: str, key: str) -> str:","    \"\"\"Read a text object from S3 and decode to UTF-8.\"\"\"","    obj = s3.get_object(Bucket=bucket, Key=key)","    return obj[\"Body\"].read().decode(\"utf-8\")","","","def build_prompt(context: str, question: str) -> str:","    \"\"\"Create the strict three-sentence insurance Q&A prompt.\"\"\"","    return f\"\"\"","You are an expert insurance-policy assistant. Use **ONLY** the text in the CONTEXT to answer.","","────────────────────────────────","RULES","1. Reply with valid JSON containing a single key \"answer\".","2. \"answer\" must be **exactly three short sentences** (≈ ≤20 words each):","   • Sentence 1 – Begin with **Yes** or **No** and state the conclusion.","   • Sentence 2 – Cite a single piece of evidence (section title, clause, or page).","3. Output **nothing** outside that JSON object.","","────────────────────────────────","CONTEXT","{context}","","────────────────────────────────","QUESTION","{question}","","Return only the JSON object described in rule 1.","\"\"\".strip()","","","def query_sambanova(prompt: str) -> str:","    \"\"\"Send the prompt to SambaNova and return the raw assistant message (JSON string).\"\"\"","    completion = client.chat.completions.create(","        model=MODEL_ID,","        messages=[{\"role\": \"user\", \"content\": prompt}],","        temperature=0,","        top_p=0.9,","    )","    return completion.choices[0].message.content","","","# ─────────────────────────────────────────","# ► Lambda entry-point","# ─────────────────────────────────────────","def lambda_handler(event, context):","    # 1️⃣ Parse body (works for API Gateway proxy or direct test invoke)","    try:","        body = event.get(\"body\", event)           # fallback to direct-style event","        if isinstance(body, str):","            body = json.loads(body)","        question = body[\"question\"]               # KeyError → handled by except","    except Exception as exc:","        return {","            \"statusCode\": 400,","            \"body\": json.dumps(f\"Invalid request structure: {exc}\")","        }","","    # 2️⃣ Aggregate all parsed PDF text into one CONTEXT string","    combined_text = \"\"","    for key in list_txt_files(PARSED_BUCKET):","        try:","            combined_text += f\"\\n\\n--- {key} ---\\n\\n{read_txt(PARSED_BUCKET, key)}\"","        except Exception as exc:","            combined_text += f\"\\n\\n--- Error reading {key}: {exc} ---\\n\\n\"","","    # 3️⃣ Build prompt, query LLM","    prompt       = build_prompt(combined_text, question)","    answer_json  = query_sambanova(prompt)        # already JSON per our prompt","","    # 4️⃣ Return straight through (CORS-friendly headers for API Gateway)","    return {","        \"statusCode\": 200,","        \"headers\": {","            \"Access-Control-Allow-Origin\":  \"*\",","            \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",","            \"Access-Control-Allow-Headers\": \"Content-Type\",","        },","        \"body\": answer_json","    }"],"id":90},{"start":{"row":0,"column":0},"end":{"row":98,"column":0},"action":"insert","lines":["import json, os, boto3","from openai import OpenAI","","# ─── Config via env-vars ──────────────────────────────────────────────","PARSED_BUCKET       = os.environ.get(\"PARSED_BUCKET\", \"elroy-and-co-insurance-docs-parsed\")","SAMBANOVA_API_KEY   = os.environ[\"SAMBANOVA_API_KEY\"]","SAMBANOVA_API_BASE  = os.environ.get(\"SAMBANOVA_API_BASE\", \"https://api.sambanova.ai/v1\")","MODEL_ID            = os.environ.get(\"MODEL_ID\", \"Meta-Llama-3.3-70B-Instruct\")","","# 0-to-disable, or e.g. 1500 to return first 1 500 chars only","PROMPT_PREVIEW_LEN  = int(os.environ.get(\"PROMPT_PREVIEW_LEN\", \"0\"))","","# ─── Clients ─────────────────────────────────────────────────────────","s3      = boto3.client(\"s3\")","client  = OpenAI(api_key=SAMBANOVA_API_KEY, base_url=SAMBANOVA_API_BASE)","","# ─── Helpers ─────────────────────────────────────────────────────────","def list_txt(bucket: str) -> list[str]:","    keys = []","    paginator = s3.get_paginator(\"list_objects_v2\")","    for page in paginator.paginate(Bucket=bucket):","        keys.extend(k[\"Key\"] for k in page.get(\"Contents\", []) if k[\"Key\"].endswith(\".txt\"))","    return keys","","def read_txt(bucket: str, key: str) -> str:","    obj = s3.get_object(Bucket=bucket, Key=key)","    return obj[\"Body\"].read().decode(\"utf-8\")","","def build_prompt(context: str, question: str) -> str:","    return f\"\"\"","You are an expert insurance-policy assistant. Use **ONLY** the text in the CONTEXT to answer.","","RULES","1. Reply with valid JSON containing a single key \"answer\".","2. \"answer\" must be **exactly three short sentences** (≤ 20 words each):","   • Sentence 1 – start with Yes/No + conclusion.  ","   • Sentence 2 – cite one clause/page as evidence.  ","   • Sentence 3 – give next steps (claim form, deadline, etc.).","3. Output **nothing** outside that JSON object.","","CONTEXT","{context}","","QUESTION","{question}","","Return only the JSON object described in rule 1.","\"\"\".strip()","","def query_llm(prompt: str) -> str:","    resp = client.chat.completions.create(","        model=MODEL_ID,","        messages=[{\"role\": \"user\", \"content\": prompt}],","        temperature=0,","        top_p=0.9,","    )","    return resp.choices[0].message.content","","# ─── Lambda entry-point ───────────────────────────────────────────────","def lambda_handler(event, context):","    # 1. Parse request","    try:","        body = event.get(\"body\", event)","        if isinstance(body, str):","            body = json.loads(body)","        question = body[\"question\"]","    except Exception as exc:","        return {\"statusCode\": 400, \"body\": json.dumps(f\"Invalid request: {exc}\")}","","    # 2. Assemble context from S3","    context_txt = \"\"","    for key in list_txt(PARSED_BUCKET):","        try:","            context_txt += f\"\\n\\n--- {key} ---\\n\\n{read_txt(PARSED_BUCKET, key)}\"","        except Exception as exc:","            context_txt += f\"\\n\\n--- Error reading {key}: {exc} ---\\n\\n\"","","    # 3. Build prompt & query model","    prompt = build_prompt(context_txt, question)","    answer = query_llm(prompt)","","    # 4. Optionally truncate the prompt we echo back","    prompt_out = prompt if PROMPT_PREVIEW_LEN <= 0 else prompt[:PROMPT_PREVIEW_LEN] + \"…\"","","    # 5. Response","    return {","        \"statusCode\": 200,","        \"headers\": {","            \"Access-Control-Allow-Origin\":  \"*\",","            \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",","            \"Access-Control-Allow-Headers\": \"Content-Type\",","        },","        \"body\": json.dumps({","            \"question\": question,","            \"answer\":  answer,","            \"prompt\":  prompt_out          # ← echoed for debugging","        })","    }",""]}],[{"start":{"row":14,"column":25},"end":{"row":14,"column":42},"action":"remove","lines":["SAMBANOVA_API_KEY"],"id":91}],[{"start":{"row":14,"column":25},"end":{"row":14,"column":27},"action":"insert","lines":["\"\""],"id":92}],[{"start":{"row":14,"column":26},"end":{"row":14,"column":62},"action":"insert","lines":["d830ceb2-cd0a-464b-b6b0-82a5f5710746"],"id":93}],[{"start":{"row":35,"column":49},"end":{"row":35,"column":51},"action":"remove","lines":["  "],"id":94},{"start":{"row":36,"column":51},"end":{"row":36,"column":53},"action":"remove","lines":["  "]}],[{"start":{"row":7,"column":50},"end":{"row":7,"column":76},"action":"remove","lines":["Meta-Llama-3.3-70B-Instruc"],"id":95}],[{"start":{"row":7,"column":50},"end":{"row":7,"column":51},"action":"remove","lines":["t"],"id":96}],[{"start":{"row":7,"column":50},"end":{"row":7,"column":57},"action":"insert","lines":["QwQ-32B"],"id":97}],[{"start":{"row":0,"column":0},"end":{"row":98,"column":0},"action":"remove","lines":["import json, os, boto3","from openai import OpenAI","","# ─── Config via env-vars ──────────────────────────────────────────────","PARSED_BUCKET       = os.environ.get(\"PARSED_BUCKET\", \"elroy-and-co-insurance-docs-parsed\")","SAMBANOVA_API_KEY   = os.environ[\"SAMBANOVA_API_KEY\"]","SAMBANOVA_API_BASE  = os.environ.get(\"SAMBANOVA_API_BASE\", \"https://api.sambanova.ai/v1\")","MODEL_ID            = os.environ.get(\"MODEL_ID\", \"QwQ-32B\")","","# 0-to-disable, or e.g. 1500 to return first 1 500 chars only","PROMPT_PREVIEW_LEN  = int(os.environ.get(\"PROMPT_PREVIEW_LEN\", \"0\"))","","# ─── Clients ─────────────────────────────────────────────────────────","s3      = boto3.client(\"s3\")","client  = OpenAI(api_key=\"d830ceb2-cd0a-464b-b6b0-82a5f5710746\", base_url=SAMBANOVA_API_BASE)","","# ─── Helpers ─────────────────────────────────────────────────────────","def list_txt(bucket: str) -> list[str]:","    keys = []","    paginator = s3.get_paginator(\"list_objects_v2\")","    for page in paginator.paginate(Bucket=bucket):","        keys.extend(k[\"Key\"] for k in page.get(\"Contents\", []) if k[\"Key\"].endswith(\".txt\"))","    return keys","","def read_txt(bucket: str, key: str) -> str:","    obj = s3.get_object(Bucket=bucket, Key=key)","    return obj[\"Body\"].read().decode(\"utf-8\")","","def build_prompt(context: str, question: str) -> str:","    return f\"\"\"","You are an expert insurance-policy assistant. Use **ONLY** the text in the CONTEXT to answer.","","RULES","1. Reply with valid JSON containing a single key \"answer\".","2. \"answer\" must be **exactly three short sentences** (≤ 20 words each):","   • Sentence 1 – start with Yes/No + conclusion.","   • Sentence 2 – cite one clause/page as evidence.","   • Sentence 3 – give next steps (claim form, deadline, etc.).","3. Output **nothing** outside that JSON object.","","CONTEXT","{context}","","QUESTION","{question}","","Return only the JSON object described in rule 1.","\"\"\".strip()","","def query_llm(prompt: str) -> str:","    resp = client.chat.completions.create(","        model=MODEL_ID,","        messages=[{\"role\": \"user\", \"content\": prompt}],","        temperature=0,","        top_p=0.9,","    )","    return resp.choices[0].message.content","","# ─── Lambda entry-point ───────────────────────────────────────────────","def lambda_handler(event, context):","    # 1. Parse request","    try:","        body = event.get(\"body\", event)","        if isinstance(body, str):","            body = json.loads(body)","        question = body[\"question\"]","    except Exception as exc:","        return {\"statusCode\": 400, \"body\": json.dumps(f\"Invalid request: {exc}\")}","","    # 2. Assemble context from S3","    context_txt = \"\"","    for key in list_txt(PARSED_BUCKET):","        try:","            context_txt += f\"\\n\\n--- {key} ---\\n\\n{read_txt(PARSED_BUCKET, key)}\"","        except Exception as exc:","            context_txt += f\"\\n\\n--- Error reading {key}: {exc} ---\\n\\n\"","","    # 3. Build prompt & query model","    prompt = build_prompt(context_txt, question)","    answer = query_llm(prompt)","","    # 4. Optionally truncate the prompt we echo back","    prompt_out = prompt if PROMPT_PREVIEW_LEN <= 0 else prompt[:PROMPT_PREVIEW_LEN] + \"…\"","","    # 5. Response","    return {","        \"statusCode\": 200,","        \"headers\": {","            \"Access-Control-Allow-Origin\":  \"*\",","            \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",","            \"Access-Control-Allow-Headers\": \"Content-Type\",","        },","        \"body\": json.dumps({","            \"question\": question,","            \"answer\":  answer,","            \"prompt\":  prompt_out          # ← echoed for debugging","        })","    }",""],"id":98},{"start":{"row":0,"column":0},"end":{"row":144,"column":0},"action":"insert","lines":["\"\"\"","lambda_function.py  —  “Gen-Z Doctor” medical-history summariser (stateless)","","What it does","────────────","• Loads plain-text medical-history files (*.txt) from an S3 bucket.","• Builds a prompt that forces an upbeat Gen-Z doctor persona to READ those","  records and spit back a super-simple summary.","• Calls a SambaNova-hosted, OpenAI-compatible model with exponential","  back-off for 429s.","• Returns ONLY a JSON object with the three-sentence summary.","","Environment variables (defaults in parentheses)","───────────────────────────────────────────────","AWS_REGION          (us-west-2)","PARSED_BUCKET       (medical-history-parsed)      # put your .txt files here","MODEL_ID            (QwQ-32B)","SAMBANOVA_API_KEY   (set this!)                   # your key","SAMBANOVA_API_BASE  (https://api.sambanova.ai/v1)","PROMPT_PREVIEW_LEN  (0)                           # >0 prints first N chars","MAX_RETRIES         (4)                           # LLM retry attempts","BASE_DELAY          (1.5)                         # sec for exponential back-off","\"\"\"","","import json, os, time, random","import boto3","from openai import OpenAI, RateLimitError","","# ─── Config ──────────────────────────────────────────────────────────","REGION            = os.getenv(\"AWS_REGION\", \"us-west-2\")","PARSED_BUCKET     = os.getenv(\"PARSED_BUCKET\", \"medical-history-parsed\")","","MODEL_ID          = os.getenv(\"MODEL_ID\", \"QwQ-32B\")","SAMBANOVA_API_KEY = os.getenv(\"SAMBANOVA_API_KEY\", \"REPLACE_ME\")","SAMBANOVA_API_BASE= os.getenv(\"SAMBANOVA_API_BASE\", \"https://api.sambanova.ai/v1\")","","PROMPT_PREVIEW_LEN= int(os.getenv(\"PROMPT_PREVIEW_LEN\", \"0\"))","MAX_RETRIES       = int(os.getenv(\"MAX_RETRIES\", \"4\"))","BASE_DELAY        = float(os.getenv(\"BASE_DELAY\", \"1.5\"))","","# ─── AWS & model clients ─────────────────────────────────────────────","s3  = boto3.client(\"s3\", region_name=REGION)","ai  = OpenAI(api_key=SAMBANOVA_API_KEY, base_url=SAMBANOVA_API_BASE)","","# ─── Helpers: S3 ------------------------------------------------------","def list_txt(bucket: str):","    keys, pag = [], s3.get_paginator(\"list_objects_v2\")","    for page in pag.paginate(Bucket=bucket):","        keys += [o[\"Key\"] for o in page.get(\"Contents\", []) if o[\"Key\"].endswith(\".txt\")]","    return keys","","def read_txt(bucket: str, key: str) -> str:","    return s3.get_object(Bucket=bucket, Key=key)[\"Body\"].read().decode()","","# ─── Prompt builder ---------------------------------------------------","def build_prompt(context: str, question: str) -> str:","    \"\"\"","    Persona: upbeat Gen-Z doctor translating medical history into simple words.","    Output: JSON with one key \"answer\", exactly three ≤20-word sentences.","    \"\"\"","    return f\"\"\"","You’re an upbeat Gen-Z doctor. Use ONLY the text in CONTEXT to explain the patient’s medical history in plain, friendly terms.","","OUTPUT RULES","1. Return valid JSON with a single key \"answer\".","2. \"answer\" = exactly three sentences (each ≤20 words):","   • Sentence 1 – quick vibe-check summary (“Yes, overall you’re healthy” / “No, chronic stuff to watch”).","   • Sentence 2 – cite one date/page/section for proof (“See 2023-05 blood panel p.2”).","   • Sentence 3 – chill next step (“Book a GP chat this month”).","3. No other keys, markdown, or explanations.","4. Kill special characters, keep it casual + crystal-clear.","","CONTEXT","{context}","","QUESTION","{question}","","Return ONLY the JSON object described above.","\"\"\".strip()","","# ─── LLM call with retry/back-off ------------------------------------","def ask_llm(prompt: str) -> str:","    for attempt in range(MAX_RETRIES):","        try:","            resp = ai.chat.completions.create(","                model       = MODEL_ID,","                messages    = [{\"role\": \"user\", \"content\": prompt}],","                temperature = 0.0,","                top_p       = 0.9,","            )","            return resp.choices[0].message.content","","        except RateLimitError:","            if attempt == MAX_RETRIES - 1:","                raise","            delay = BASE_DELAY ** attempt + random.random()","            print(f\"[retry] rate-limited → waiting {delay:.1f}s\")","            time.sleep(delay)","","# ─── Lambda entry-point ----------------------------------------------","def lambda_handler(event, _ctx):","    # 1 — parse request","    body = event.get(\"body\", event)","    if isinstance(body, str):","        body = json.loads(body)","    question = body.get(\"question\", \"Please summarise my medical history.\")","","    # 2 — pull context from S3","    context_txt = \"\"","    for k in list_txt(PARSED_BUCKET):","        try:","            context_txt += f\"\\n\\n--- {k} ---\\n\\n{read_txt(PARSED_BUCKET, k)}\"","        except Exception as e:","            context_txt += f\"\\n\\n--- Error reading {k}: {e} ---\\n\\n\"","","    # 3 — build prompt & query model","    prompt    = build_prompt(context_txt, question)","    raw_reply = ask_llm(prompt)","","    # 4 — extract clean answer","    try:","        final_answer = json.loads(raw_reply)[\"answer\"]","    except Exception:","        brace = raw_reply.rfind(\"{\")","        final_answer = json.loads(raw_reply[brace:]).get(\"answer\", raw_reply) if brace != -1 else raw_reply","","    # 5 — optional prompt preview","    if PROMPT_PREVIEW_LEN:","        print(\"PROMPT PREVIEW:\\n\", prompt[:PROMPT_PREVIEW_LEN] + (\"…\" if len(prompt) > PROMPT_PREVIEW_LEN else \"\"))","","    # 6 — HTTP response","    return {","        \"statusCode\": 200,","        \"headers\": {","            \"Access-Control-Allow-Origin\":  \"*\",","            \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",","            \"Access-Control-Allow-Headers\": \"Content-Type\",","        },","        \"body\": json.dumps({","            \"question\": question,","            \"answer\":   final_answer","        })","    }",""]}],[{"start":{"row":30,"column":49},"end":{"row":30,"column":68},"action":"remove","lines":["edical-history-pars"],"id":104}],[{"start":{"row":30,"column":49},"end":{"row":30,"column":50},"action":"remove","lines":["e"],"id":105}],[{"start":{"row":30,"column":49},"end":{"row":30,"column":50},"action":"remove","lines":["d"],"id":106},{"start":{"row":30,"column":48},"end":{"row":30,"column":49},"action":"remove","lines":["m"]}],[{"start":{"row":30,"column":48},"end":{"row":30,"column":77},"action":"insert","lines":["elroy-and-co-medical-history "],"id":107}],[{"start":{"row":30,"column":77},"end":{"row":30,"column":78},"action":"insert","lines":["s"],"id":108}],[{"start":{"row":30,"column":77},"end":{"row":30,"column":78},"action":"remove","lines":["s"],"id":109},{"start":{"row":30,"column":76},"end":{"row":30,"column":77},"action":"remove","lines":[" "]}],[{"start":{"row":33,"column":52},"end":{"row":33,"column":62},"action":"remove","lines":["REPLACE_ME"],"id":110}],[{"start":{"row":33,"column":52},"end":{"row":33,"column":88},"action":"insert","lines":["d830ceb2-cd0a-464b-b6b0-82a5f5710746"],"id":111}],[{"start":{"row":32,"column":49},"end":{"row":32,"column":50},"action":"remove","lines":["B"],"id":128},{"start":{"row":32,"column":48},"end":{"row":32,"column":49},"action":"remove","lines":["2"]},{"start":{"row":32,"column":47},"end":{"row":32,"column":48},"action":"remove","lines":["3"]},{"start":{"row":32,"column":46},"end":{"row":32,"column":47},"action":"remove","lines":["-"]},{"start":{"row":32,"column":45},"end":{"row":32,"column":46},"action":"remove","lines":["Q"]},{"start":{"row":32,"column":44},"end":{"row":32,"column":45},"action":"remove","lines":["w"]},{"start":{"row":32,"column":43},"end":{"row":32,"column":44},"action":"remove","lines":["Q"]}],[{"start":{"row":32,"column":43},"end":{"row":32,"column":72},"action":"insert","lines":["DeepSeek-R1-Distill-Llama-70B"],"id":129}],[{"start":{"row":0,"column":0},"end":{"row":144,"column":0},"action":"remove","lines":["\"\"\"","lambda_function.py  —  “Gen-Z Doctor” medical-history summariser (stateless)","","What it does","────────────","• Loads plain-text medical-history files (*.txt) from an S3 bucket.","• Builds a prompt that forces an upbeat Gen-Z doctor persona to READ those","  records and spit back a super-simple summary.","• Calls a SambaNova-hosted, OpenAI-compatible model with exponential","  back-off for 429s.","• Returns ONLY a JSON object with the three-sentence summary.","","Environment variables (defaults in parentheses)","───────────────────────────────────────────────","AWS_REGION          (us-west-2)","PARSED_BUCKET       (medical-history-parsed)      # put your .txt files here","MODEL_ID            (QwQ-32B)","SAMBANOVA_API_KEY   (set this!)                   # your key","SAMBANOVA_API_BASE  (https://api.sambanova.ai/v1)","PROMPT_PREVIEW_LEN  (0)                           # >0 prints first N chars","MAX_RETRIES         (4)                           # LLM retry attempts","BASE_DELAY          (1.5)                         # sec for exponential back-off","\"\"\"","","import json, os, time, random","import boto3","from openai import OpenAI, RateLimitError","","# ─── Config ──────────────────────────────────────────────────────────","REGION            = os.getenv(\"AWS_REGION\", \"us-west-2\")","PARSED_BUCKET     = os.getenv(\"PARSED_BUCKET\", \"elroy-and-co-medical-history\")","","MODEL_ID          = os.getenv(\"MODEL_ID\", \"DeepSeek-R1-Distill-Llama-70B\")","SAMBANOVA_API_KEY = os.getenv(\"SAMBANOVA_API_KEY\", \"d830ceb2-cd0a-464b-b6b0-82a5f5710746\")","SAMBANOVA_API_BASE= os.getenv(\"SAMBANOVA_API_BASE\", \"https://api.sambanova.ai/v1\")","","PROMPT_PREVIEW_LEN= int(os.getenv(\"PROMPT_PREVIEW_LEN\", \"0\"))","MAX_RETRIES       = int(os.getenv(\"MAX_RETRIES\", \"4\"))","BASE_DELAY        = float(os.getenv(\"BASE_DELAY\", \"1.5\"))","","# ─── AWS & model clients ─────────────────────────────────────────────","s3  = boto3.client(\"s3\", region_name=REGION)","ai  = OpenAI(api_key=SAMBANOVA_API_KEY, base_url=SAMBANOVA_API_BASE)","","# ─── Helpers: S3 ------------------------------------------------------","def list_txt(bucket: str):","    keys, pag = [], s3.get_paginator(\"list_objects_v2\")","    for page in pag.paginate(Bucket=bucket):","        keys += [o[\"Key\"] for o in page.get(\"Contents\", []) if o[\"Key\"].endswith(\".txt\")]","    return keys","","def read_txt(bucket: str, key: str) -> str:","    return s3.get_object(Bucket=bucket, Key=key)[\"Body\"].read().decode()","","# ─── Prompt builder ---------------------------------------------------","def build_prompt(context: str, question: str) -> str:","    \"\"\"","    Persona: upbeat Gen-Z doctor translating medical history into simple words.","    Output: JSON with one key \"answer\", exactly three ≤20-word sentences.","    \"\"\"","    return f\"\"\"","You’re an upbeat Gen-Z doctor. Use ONLY the text in CONTEXT to explain the patient’s medical history in plain, friendly terms.","","OUTPUT RULES","1. Return valid JSON with a single key \"answer\".","2. \"answer\" = exactly three sentences (each ≤20 words):","   • Sentence 1 – quick vibe-check summary (“Yes, overall you’re healthy” / “No, chronic stuff to watch”).","   • Sentence 2 – cite one date/page/section for proof (“See 2023-05 blood panel p.2”).","   • Sentence 3 – chill next step (“Book a GP chat this month”).","3. No other keys, markdown, or explanations.","4. Kill special characters, keep it casual + crystal-clear.","","CONTEXT","{context}","","QUESTION","{question}","","Return ONLY the JSON object described above.","\"\"\".strip()","","# ─── LLM call with retry/back-off ------------------------------------","def ask_llm(prompt: str) -> str:","    for attempt in range(MAX_RETRIES):","        try:","            resp = ai.chat.completions.create(","                model       = MODEL_ID,","                messages    = [{\"role\": \"user\", \"content\": prompt}],","                temperature = 0.0,","                top_p       = 0.9,","            )","            return resp.choices[0].message.content","","        except RateLimitError:","            if attempt == MAX_RETRIES - 1:","                raise","            delay = BASE_DELAY ** attempt + random.random()","            print(f\"[retry] rate-limited → waiting {delay:.1f}s\")","            time.sleep(delay)","","# ─── Lambda entry-point ----------------------------------------------","def lambda_handler(event, _ctx):","    # 1 — parse request","    body = event.get(\"body\", event)","    if isinstance(body, str):","        body = json.loads(body)","    question = body.get(\"question\", \"Please summarise my medical history.\")","","    # 2 — pull context from S3","    context_txt = \"\"","    for k in list_txt(PARSED_BUCKET):","        try:","            context_txt += f\"\\n\\n--- {k} ---\\n\\n{read_txt(PARSED_BUCKET, k)}\"","        except Exception as e:","            context_txt += f\"\\n\\n--- Error reading {k}: {e} ---\\n\\n\"","","    # 3 — build prompt & query model","    prompt    = build_prompt(context_txt, question)","    raw_reply = ask_llm(prompt)","","    # 4 — extract clean answer","    try:","        final_answer = json.loads(raw_reply)[\"answer\"]","    except Exception:","        brace = raw_reply.rfind(\"{\")","        final_answer = json.loads(raw_reply[brace:]).get(\"answer\", raw_reply) if brace != -1 else raw_reply","","    # 5 — optional prompt preview","    if PROMPT_PREVIEW_LEN:","        print(\"PROMPT PREVIEW:\\n\", prompt[:PROMPT_PREVIEW_LEN] + (\"…\" if len(prompt) > PROMPT_PREVIEW_LEN else \"\"))","","    # 6 — HTTP response","    return {","        \"statusCode\": 200,","        \"headers\": {","            \"Access-Control-Allow-Origin\":  \"*\",","            \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",","            \"Access-Control-Allow-Headers\": \"Content-Type\",","        },","        \"body\": json.dumps({","            \"question\": question,","            \"answer\":   final_answer","        })","    }",""],"id":130},{"start":{"row":0,"column":0},"end":{"row":142,"column":0},"action":"insert","lines":["\"\"\"","lambda_function.py — Gen-Z Doctor summariser (CSV edition, robust JSON extractor)","───────────────────────────────────────────────────────────────────────────────","Same behaviour as before, but:","• Reads *.csv medical-history files.","• Safer JSON-parsing: strips whatever the LLM adds before/after the object.","\"\"\"","import json, os, time, random, re","import boto3","from openai import OpenAI, RateLimitError","","# ─── Config ──────────────────────────────────────────────────────────","REGION            = os.getenv(\"AWS_REGION\", \"us-west-2\")","PARSED_BUCKET     = os.getenv(\"PARSED_BUCKET\", \"elroy-and-co-medical-history\")","MODEL_ID          = os.getenv(\"MODEL_ID\", \"DeepSeek-R1-Distill-Llama-70B\")","SAMBANOVA_API_KEY = os.getenv(\"SAMBANOVA_API_KEY\")","SAMBANOVA_API_BASE= os.getenv(\"SAMBANOVA_API_BASE\", \"https://api.sambanova.ai/v1\")","","PROMPT_PREVIEW_LEN= int(os.getenv(\"PROMPT_PREVIEW_LEN\", \"0\"))","MAX_RETRIES       = int(os.getenv(\"MAX_RETRIES\", \"4\"))","BASE_DELAY        = float(os.getenv(\"BASE_DELAY\", \"1.5\"))","","# ─── AWS & model clients ─────────────────────────────────────────────","s3  = boto3.client(\"s3\", region_name=REGION)","ai  = OpenAI(api_key=SAMBANOVA_API_KEY, base_url=SAMBANOVA_API_BASE)","","# ─── Helpers: S3 ------------------------------------------------------","def list_csv(bucket: str) -> list[str]:","    keys, pag = [], s3.get_paginator(\"list_objects_v2\")","    for page in pag.paginate(Bucket=bucket):","        keys += [o[\"Key\"] for o in page.get(\"Contents\", [])","                 if o[\"Key\"].lower().endswith(\".csv\")]","    return keys","","def read_csv(bucket: str, key: str) -> str:","    return s3.get_object(Bucket=bucket, Key=key)[\"Body\"].read().decode()","","# ─── Prompt builder ---------------------------------------------------","def build_prompt(context: str, question: str) -> str:","    return f\"\"\"","You’re an upbeat Gen-Z doctor. Use ONLY the text in CONTEXT to explain the patient’s medical history in plain, friendly terms.","","OUTPUT RULES","1. Return valid JSON with a single key \"answer\".","2. \"answer\" = exactly three sentences (each ≤20 words):","   • Sentence 1 – quick vibe-check summary (“Yes, overall you’re healthy” / “No, chronic stuff to watch”).","   • Sentence 2 – cite one date/page/section for proof (“See 2023-05 blood panel p.2”).","   • Sentence 3 – chill next step (“Book a GP chat this month”).","3. No other keys, markdown, or explanations.","4. Kill special characters, keep it casual + crystal-clear.","5. Just use text dont bold","","CONTEXT","{context}","","QUESTION","{question}","","Return ONLY the JSON object described above.","\"\"\".strip()","","# ─── LLM call with retry/back-off ------------------------------------","def ask_llm(prompt: str) -> str:","    for attempt in range(MAX_RETRIES):","        try:","            resp = ai.chat.completions.create(","                model       = MODEL_ID,","                messages    = [{\"role\": \"user\", \"content\": prompt}],","                temperature = 0.0,","                top_p       = 0.9,","            )","            return resp.choices[0].message.content","        except RateLimitError:","            if attempt == MAX_RETRIES - 1:","                raise","            delay = BASE_DELAY ** attempt + random.random()","            print(f\"[retry] rate-limited → waiting {delay:.1f}s\")","            time.sleep(delay)","","# ─── Robust JSON extractor -------------------------------------------","def extract_json(raw: str) -> dict:","    \"\"\"","    Finds the first top-level {...} block and loads it.","    If nothing parses, returns {\"answer\": raw.strip()}.","    \"\"\"","    start = raw.find(\"{\")","    if start == -1:","        return {\"answer\": raw.strip()}","","    depth = 0","    for idx, ch in enumerate(raw[start:]):","        if ch == \"{\":","            depth += 1","        elif ch == \"}\":","            depth -= 1","            if depth == 0:","                try:","                    return json.loads(raw[start:start + idx + 1])","                except json.JSONDecodeError:","                    break  # malformed, fall through","    return {\"answer\": raw.strip()}","","# ─── Lambda entry-point ----------------------------------------------","def lambda_handler(event, _ctx):","    # 1 — parse request","    body = event.get(\"body\", event)","    if isinstance(body, str):","        body = json.loads(body)","    question = body.get(\"question\", \"Please summarise my medical history.\")","","    # 2 — pull context from S3","    context_txt = \"\"","    for k in list_csv(PARSED_BUCKET):","        try:","            context_txt += f\"\\n\\n--- {k} ---\\n\\n{read_csv(PARSED_BUCKET, k)}\"","        except Exception as e:","            context_txt += f\"\\n\\n--- Error reading {k}: {e} ---\\n\\n\"","","    # 3 — build prompt & query model","    prompt    = build_prompt(context_txt, question)","    raw_reply = ask_llm(prompt)","","    # 4 — extract clean answer (robust)","    final_answer = extract_json(raw_reply).get(\"answer\")","","    # 5 — optional prompt preview","    if PROMPT_PREVIEW_LEN:","        print(\"PROMPT PREVIEW:\\n\", prompt[:PROMPT_PREVIEW_LEN] + (\"…\" if len(prompt) > PROMPT_PREVIEW_LEN else \"\"))","","    # 6 — HTTP response","    return {","        \"statusCode\": 200,","        \"headers\": {","            \"Access-Control-Allow-Origin\":  \"*\",","            \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",","            \"Access-Control-Allow-Headers\": \"Content-Type\",","        },","        \"body\": json.dumps({","            \"question\": question,","            \"answer\":   final_answer","        })","    }",""]}],[{"start":{"row":0,"column":0},"end":{"row":142,"column":0},"action":"remove","lines":["\"\"\"","lambda_function.py — Gen-Z Doctor summariser (CSV edition, robust JSON extractor)","───────────────────────────────────────────────────────────────────────────────","Same behaviour as before, but:","• Reads *.csv medical-history files.","• Safer JSON-parsing: strips whatever the LLM adds before/after the object.","\"\"\"","import json, os, time, random, re","import boto3","from openai import OpenAI, RateLimitError","","# ─── Config ──────────────────────────────────────────────────────────","REGION            = os.getenv(\"AWS_REGION\", \"us-west-2\")","PARSED_BUCKET     = os.getenv(\"PARSED_BUCKET\", \"elroy-and-co-medical-history\")","MODEL_ID          = os.getenv(\"MODEL_ID\", \"DeepSeek-R1-Distill-Llama-70B\")","SAMBANOVA_API_KEY = os.getenv(\"SAMBANOVA_API_KEY\")","SAMBANOVA_API_BASE= os.getenv(\"SAMBANOVA_API_BASE\", \"https://api.sambanova.ai/v1\")","","PROMPT_PREVIEW_LEN= int(os.getenv(\"PROMPT_PREVIEW_LEN\", \"0\"))","MAX_RETRIES       = int(os.getenv(\"MAX_RETRIES\", \"4\"))","BASE_DELAY        = float(os.getenv(\"BASE_DELAY\", \"1.5\"))","","# ─── AWS & model clients ─────────────────────────────────────────────","s3  = boto3.client(\"s3\", region_name=REGION)","ai  = OpenAI(api_key=SAMBANOVA_API_KEY, base_url=SAMBANOVA_API_BASE)","","# ─── Helpers: S3 ------------------------------------------------------","def list_csv(bucket: str) -> list[str]:","    keys, pag = [], s3.get_paginator(\"list_objects_v2\")","    for page in pag.paginate(Bucket=bucket):","        keys += [o[\"Key\"] for o in page.get(\"Contents\", [])","                 if o[\"Key\"].lower().endswith(\".csv\")]","    return keys","","def read_csv(bucket: str, key: str) -> str:","    return s3.get_object(Bucket=bucket, Key=key)[\"Body\"].read().decode()","","# ─── Prompt builder ---------------------------------------------------","def build_prompt(context: str, question: str) -> str:","    return f\"\"\"","You’re an upbeat Gen-Z doctor. Use ONLY the text in CONTEXT to explain the patient’s medical history in plain, friendly terms.","","OUTPUT RULES","1. Return valid JSON with a single key \"answer\".","2. \"answer\" = exactly three sentences (each ≤20 words):","   • Sentence 1 – quick vibe-check summary (“Yes, overall you’re healthy” / “No, chronic stuff to watch”).","   • Sentence 2 – cite one date/page/section for proof (“See 2023-05 blood panel p.2”).","   • Sentence 3 – chill next step (“Book a GP chat this month”).","3. No other keys, markdown, or explanations.","4. Kill special characters, keep it casual + crystal-clear.","5. Just use text dont bold","","CONTEXT","{context}","","QUESTION","{question}","","Return ONLY the JSON object described above.","\"\"\".strip()","","# ─── LLM call with retry/back-off ------------------------------------","def ask_llm(prompt: str) -> str:","    for attempt in range(MAX_RETRIES):","        try:","            resp = ai.chat.completions.create(","                model       = MODEL_ID,","                messages    = [{\"role\": \"user\", \"content\": prompt}],","                temperature = 0.0,","                top_p       = 0.9,","            )","            return resp.choices[0].message.content","        except RateLimitError:","            if attempt == MAX_RETRIES - 1:","                raise","            delay = BASE_DELAY ** attempt + random.random()","            print(f\"[retry] rate-limited → waiting {delay:.1f}s\")","            time.sleep(delay)","","# ─── Robust JSON extractor -------------------------------------------","def extract_json(raw: str) -> dict:","    \"\"\"","    Finds the first top-level {...} block and loads it.","    If nothing parses, returns {\"answer\": raw.strip()}.","    \"\"\"","    start = raw.find(\"{\")","    if start == -1:","        return {\"answer\": raw.strip()}","","    depth = 0","    for idx, ch in enumerate(raw[start:]):","        if ch == \"{\":","            depth += 1","        elif ch == \"}\":","            depth -= 1","            if depth == 0:","                try:","                    return json.loads(raw[start:start + idx + 1])","                except json.JSONDecodeError:","                    break  # malformed, fall through","    return {\"answer\": raw.strip()}","","# ─── Lambda entry-point ----------------------------------------------","def lambda_handler(event, _ctx):","    # 1 — parse request","    body = event.get(\"body\", event)","    if isinstance(body, str):","        body = json.loads(body)","    question = body.get(\"question\", \"Please summarise my medical history.\")","","    # 2 — pull context from S3","    context_txt = \"\"","    for k in list_csv(PARSED_BUCKET):","        try:","            context_txt += f\"\\n\\n--- {k} ---\\n\\n{read_csv(PARSED_BUCKET, k)}\"","        except Exception as e:","            context_txt += f\"\\n\\n--- Error reading {k}: {e} ---\\n\\n\"","","    # 3 — build prompt & query model","    prompt    = build_prompt(context_txt, question)","    raw_reply = ask_llm(prompt)","","    # 4 — extract clean answer (robust)","    final_answer = extract_json(raw_reply).get(\"answer\")","","    # 5 — optional prompt preview","    if PROMPT_PREVIEW_LEN:","        print(\"PROMPT PREVIEW:\\n\", prompt[:PROMPT_PREVIEW_LEN] + (\"…\" if len(prompt) > PROMPT_PREVIEW_LEN else \"\"))","","    # 6 — HTTP response","    return {","        \"statusCode\": 200,","        \"headers\": {","            \"Access-Control-Allow-Origin\":  \"*\",","            \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",","            \"Access-Control-Allow-Headers\": \"Content-Type\",","        },","        \"body\": json.dumps({","            \"question\": question,","            \"answer\":   final_answer","        })","    }",""],"id":131},{"start":{"row":0,"column":0},"end":{"row":162,"column":0},"action":"insert","lines":["\"\"\"","lambda_function.py — Gen-Z Doctor medical-history summariser (TXT edition)","","What it does","────────────","• Loads medical-history files (*.txt) from an S3 bucket.","• Builds a prompt that forces an upbeat Gen-Z doctor persona to READ those","  records and return a super-simple summary.","• Calls a SambaNova-hosted, OpenAI-compatible model with exponential","  back-off on 429 throttling.","• Sends back ONLY a JSON object containing the three-sentence summary.","","Environment variables (defaults in parentheses)","───────────────────────────────────────────────","AWS_REGION          (us-west-2)","PARSED_BUCKET       (medical-history-parsed)    # put your .txt files here","MODEL_ID            (QwQ-32B)","SAMBANOVA_API_KEY   (set this!)                 # your key","SAMBANOVA_API_BASE  (https://api.sambanova.ai/v1)","PROMPT_PREVIEW_LEN  (0)                         # >0 prints first N chars of prompt","MAX_RETRIES         (4)                         # LLM retry attempts","BASE_DELAY          (1.5)                       # sec base for exponential back-off","\"\"\"","","import json, os, time, random","import boto3","from openai import OpenAI, RateLimitError","","# ─── Config ──────────────────────────────────────────────────────────","REGION            = os.getenv(\"AWS_REGION\", \"us-west-2\")","PARSED_BUCKET     = os.getenv(\"PARSED_BUCKET\", \"elroy-and-co-medical-history\")","MODEL_ID          = os.getenv(\"MODEL_ID\", \"DeepSeek-R1-Distill-Llama-70B\")","SAMBANOVA_API_KEY = os.getenv(\"SAMBANOVA_API_KEY\")","SAMBANOVA_API_BASE= os.getenv(\"SAMBANOVA_API_BASE\", \"https://api.sambanova.ai/v1\")","","PROMPT_PREVIEW_LEN= int(os.getenv(\"PROMPT_PREVIEW_LEN\", \"0\"))","MAX_RETRIES       = int(os.getenv(\"MAX_RETRIES\", \"4\"))","BASE_DELAY        = float(os.getenv(\"BASE_DELAY\", \"1.5\"))","","# ─── AWS & model clients ─────────────────────────────────────────────","s3  = boto3.client(\"s3\", region_name=REGION)","ai  = OpenAI(api_key=SAMBANOVA_API_KEY, base_url=SAMBANOVA_API_BASE)","","# ─── Helpers: S3 ------------------------------------------------------","def list_txt(bucket: str) -> list[str]:","    \"\"\"Return every *.txt key in *bucket* (case-insensitive).\"\"\"","    keys, pag = [], s3.get_paginator(\"list_objects_v2\")","    for page in pag.paginate(Bucket=bucket):","        keys += [o[\"Key\"] for o in page.get(\"Contents\", [])","                 if o[\"Key\"].lower().endswith(\".txt\")]","    return keys","","def read_txt(bucket: str, key: str) -> str:","    \"\"\"Load a TXT file as raw text (newlines preserved).\"\"\"","    return s3.get_object(Bucket=bucket, Key=key)[\"Body\"].read().decode()","","# ─── Prompt builder ---------------------------------------------------","def build_prompt(context: str, question: str) -> str:","    return f\"\"\"","You’re an upbeat Gen-Z doctor. Use ONLY the text in CONTEXT to explain the patient’s medical history in plain, friendly terms.","","OUTPUT RULES","1. Return valid JSON with a single key \"answer\".","2. \"answer\" = exactly three sentences (each ≤20 words):","   • Sentence 1 – quick vibe-check (“Yes, overall you’re healthy” / “No, chronic stuff to watch”).","   • Sentence 2 – cite one date/page/section for proof (“See 2023-05 blood panel p.2”).","   • Sentence 3 – chill next step (“Book a GP chat this month”).","3. No other keys, markdown, or explanations.","4. Kill special characters, keep it casual + crystal-clear.","5. Just use text dont bold","","CONTEXT","{context}","","QUESTION","{question}","","Return ONLY the JSON object described above.","\"\"\".strip()","","# ─── LLM call with retry/back-off ------------------------------------","def ask_llm(prompt: str) -> str:","    for attempt in range(MAX_RETRIES):","        try:","            resp = ai.chat.completions.create(","                model       = MODEL_ID,","                messages    = [{\"role\": \"user\", \"content\": prompt}],","                temperature = 0.0,","                top_p       = 0.9,","            )","            return resp.choices[0].message.content","        except RateLimitError:","            if attempt == MAX_RETRIES - 1:","                raise","            delay = BASE_DELAY ** attempt + random.random()","            print(f\"[retry] rate-limited → waiting {delay:.1f}s\")","            time.sleep(delay)","","# ─── Robust JSON extractor -------------------------------------------","def extract_json(raw: str) -> dict:","    \"\"\"","    Finds the first top-level {...} block and loads it.","    If nothing parses, returns {\"answer\": raw.strip()}.","    \"\"\"","    start = raw.find(\"{\")","    if start == -1:","        return {\"answer\": raw.strip()}","","    depth = 0","    for idx, ch in enumerate(raw[start:]):","        if ch == \"{\":","            depth += 1","        elif ch == \"}\":","            depth -= 1","            if depth == 0:","                try:","                    return json.loads(raw[start:start + idx + 1])","                except json.JSONDecodeError:","                    break","    return {\"answer\": raw.strip()}","","# ─── Lambda entry-point ----------------------------------------------","def lambda_handler(event, _ctx):","    # 1 — parse request","    body = event.get(\"body\", event)","    if isinstance(body, str):","        body = json.loads(body)","    question = body.get(\"question\", \"Please summarise my medical history.\")","","    # 2 — pull context from S3","    context_txt = \"\"","    for k in list_txt(PARSED_BUCKET):","        try:","            context_txt += f\"\\n\\n--- {k} ---\\n\\n{read_txt(PARSED_BUCKET, k)}\"","        except Exception as e:","            context_txt += f\"\\n\\n--- Error reading {k}: {e} ---\\n\\n\"","","    # 3 — build prompt & query model","    prompt    = build_prompt(context_txt, question)","    raw_reply = ask_llm(prompt)","","    # 4 — extract clean answer","    final_answer = extract_json(raw_reply).get(\"answer\")","","    # 5 — optional prompt preview","    if PROMPT_PREVIEW_LEN:","        print(\"PROMPT PREVIEW:\\n\", prompt[:PROMPT_PREVIEW_LEN] +","              (\"…\" if len(prompt) > PROMPT_PREVIEW_LEN else \"\"))","","    # 6 — HTTP response","    return {","        \"statusCode\": 200,","        \"headers\": {","            \"Access-Control-Allow-Origin\":  \"*\",","            \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",","            \"Access-Control-Allow-Headers\": \"Content-Type\",","        },","        \"body\": json.dumps({","            \"question\": question,","            \"answer\":   final_answer","        })","    }",""]}],[{"start":{"row":0,"column":0},"end":{"row":162,"column":0},"action":"remove","lines":["\"\"\"","lambda_function.py — Gen-Z Doctor medical-history summariser (TXT edition)","","What it does","────────────","• Loads medical-history files (*.txt) from an S3 bucket.","• Builds a prompt that forces an upbeat Gen-Z doctor persona to READ those","  records and return a super-simple summary.","• Calls a SambaNova-hosted, OpenAI-compatible model with exponential","  back-off on 429 throttling.","• Sends back ONLY a JSON object containing the three-sentence summary.","","Environment variables (defaults in parentheses)","───────────────────────────────────────────────","AWS_REGION          (us-west-2)","PARSED_BUCKET       (medical-history-parsed)    # put your .txt files here","MODEL_ID            (QwQ-32B)","SAMBANOVA_API_KEY   (set this!)                 # your key","SAMBANOVA_API_BASE  (https://api.sambanova.ai/v1)","PROMPT_PREVIEW_LEN  (0)                         # >0 prints first N chars of prompt","MAX_RETRIES         (4)                         # LLM retry attempts","BASE_DELAY          (1.5)                       # sec base for exponential back-off","\"\"\"","","import json, os, time, random","import boto3","from openai import OpenAI, RateLimitError","","# ─── Config ──────────────────────────────────────────────────────────","REGION            = os.getenv(\"AWS_REGION\", \"us-west-2\")","PARSED_BUCKET     = os.getenv(\"PARSED_BUCKET\", \"elroy-and-co-medical-history\")","MODEL_ID          = os.getenv(\"MODEL_ID\", \"DeepSeek-R1-Distill-Llama-70B\")","SAMBANOVA_API_KEY = os.getenv(\"SAMBANOVA_API_KEY\")","SAMBANOVA_API_BASE= os.getenv(\"SAMBANOVA_API_BASE\", \"https://api.sambanova.ai/v1\")","","PROMPT_PREVIEW_LEN= int(os.getenv(\"PROMPT_PREVIEW_LEN\", \"0\"))","MAX_RETRIES       = int(os.getenv(\"MAX_RETRIES\", \"4\"))","BASE_DELAY        = float(os.getenv(\"BASE_DELAY\", \"1.5\"))","","# ─── AWS & model clients ─────────────────────────────────────────────","s3  = boto3.client(\"s3\", region_name=REGION)","ai  = OpenAI(api_key=SAMBANOVA_API_KEY, base_url=SAMBANOVA_API_BASE)","","# ─── Helpers: S3 ------------------------------------------------------","def list_txt(bucket: str) -> list[str]:","    \"\"\"Return every *.txt key in *bucket* (case-insensitive).\"\"\"","    keys, pag = [], s3.get_paginator(\"list_objects_v2\")","    for page in pag.paginate(Bucket=bucket):","        keys += [o[\"Key\"] for o in page.get(\"Contents\", [])","                 if o[\"Key\"].lower().endswith(\".txt\")]","    return keys","","def read_txt(bucket: str, key: str) -> str:","    \"\"\"Load a TXT file as raw text (newlines preserved).\"\"\"","    return s3.get_object(Bucket=bucket, Key=key)[\"Body\"].read().decode()","","# ─── Prompt builder ---------------------------------------------------","def build_prompt(context: str, question: str) -> str:","    return f\"\"\"","You’re an upbeat Gen-Z doctor. Use ONLY the text in CONTEXT to explain the patient’s medical history in plain, friendly terms.","","OUTPUT RULES","1. Return valid JSON with a single key \"answer\".","2. \"answer\" = exactly three sentences (each ≤20 words):","   • Sentence 1 – quick vibe-check (“Yes, overall you’re healthy” / “No, chronic stuff to watch”).","   • Sentence 2 – cite one date/page/section for proof (“See 2023-05 blood panel p.2”).","   • Sentence 3 – chill next step (“Book a GP chat this month”).","3. No other keys, markdown, or explanations.","4. Kill special characters, keep it casual + crystal-clear.","5. Just use text dont bold","","CONTEXT","{context}","","QUESTION","{question}","","Return ONLY the JSON object described above.","\"\"\".strip()","","# ─── LLM call with retry/back-off ------------------------------------","def ask_llm(prompt: str) -> str:","    for attempt in range(MAX_RETRIES):","        try:","            resp = ai.chat.completions.create(","                model       = MODEL_ID,","                messages    = [{\"role\": \"user\", \"content\": prompt}],","                temperature = 0.0,","                top_p       = 0.9,","            )","            return resp.choices[0].message.content","        except RateLimitError:","            if attempt == MAX_RETRIES - 1:","                raise","            delay = BASE_DELAY ** attempt + random.random()","            print(f\"[retry] rate-limited → waiting {delay:.1f}s\")","            time.sleep(delay)","","# ─── Robust JSON extractor -------------------------------------------","def extract_json(raw: str) -> dict:","    \"\"\"","    Finds the first top-level {...} block and loads it.","    If nothing parses, returns {\"answer\": raw.strip()}.","    \"\"\"","    start = raw.find(\"{\")","    if start == -1:","        return {\"answer\": raw.strip()}","","    depth = 0","    for idx, ch in enumerate(raw[start:]):","        if ch == \"{\":","            depth += 1","        elif ch == \"}\":","            depth -= 1","            if depth == 0:","                try:","                    return json.loads(raw[start:start + idx + 1])","                except json.JSONDecodeError:","                    break","    return {\"answer\": raw.strip()}","","# ─── Lambda entry-point ----------------------------------------------","def lambda_handler(event, _ctx):","    # 1 — parse request","    body = event.get(\"body\", event)","    if isinstance(body, str):","        body = json.loads(body)","    question = body.get(\"question\", \"Please summarise my medical history.\")","","    # 2 — pull context from S3","    context_txt = \"\"","    for k in list_txt(PARSED_BUCKET):","        try:","            context_txt += f\"\\n\\n--- {k} ---\\n\\n{read_txt(PARSED_BUCKET, k)}\"","        except Exception as e:","            context_txt += f\"\\n\\n--- Error reading {k}: {e} ---\\n\\n\"","","    # 3 — build prompt & query model","    prompt    = build_prompt(context_txt, question)","    raw_reply = ask_llm(prompt)","","    # 4 — extract clean answer","    final_answer = extract_json(raw_reply).get(\"answer\")","","    # 5 — optional prompt preview","    if PROMPT_PREVIEW_LEN:","        print(\"PROMPT PREVIEW:\\n\", prompt[:PROMPT_PREVIEW_LEN] +","              (\"…\" if len(prompt) > PROMPT_PREVIEW_LEN else \"\"))","","    # 6 — HTTP response","    return {","        \"statusCode\": 200,","        \"headers\": {","            \"Access-Control-Allow-Origin\":  \"*\",","            \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",","            \"Access-Control-Allow-Headers\": \"Content-Type\",","        },","        \"body\": json.dumps({","            \"question\": question,","            \"answer\":   final_answer","        })","    }",""],"id":132},{"start":{"row":0,"column":0},"end":{"row":128,"column":0},"action":"insert","lines":["import json, os, boto3","from openai import OpenAI","","# ── Config via env-vars ───────────────────────────────────────────────","PARSED_BUCKET       = os.getenv(\"PARSED_BUCKET\", \"elroy-and-co-medical-records\")","SAMBANOVA_API_BASE  = os.getenv(\"SAMBANOVA_API_BASE\", \"https://api.sambanova.ai/v1\")","MODEL_ID            = os.getenv(\"MODEL_ID\", \"QwQ-32B\")","# NOTE: move this key to Secrets Manager or an env var in production!","SAMBANOVA_API_KEY   = \"d830ceb2-cd0a-464b-b6b0-82a5f5710746\"","","# 0 ➜ no preview; N ➜ log first N chars of the prompt","PROMPT_PREVIEW_LEN  = int(os.getenv(\"PROMPT_PREVIEW_LEN\", \"0\"))","","# ── AWS / LLM clients ────────────────────────────────────────────────","s3      = boto3.client(\"s3\")","client  = OpenAI(api_key=SAMBANOVA_API_KEY, base_url=SAMBANOVA_API_BASE)","","# ── Helpers ───────────────────────────────────────────────────────────","def list_txt(bucket: str) -> list[str]:","    \"\"\"Return all *.txt keys in the bucket.\"\"\"","    keys, pag = [], s3.get_paginator(\"list_objects_v2\")","    for page in pag.paginate(Bucket=bucket):","        keys.extend(obj[\"Key\"] for obj in page.get(\"Contents\", [])","                     if obj[\"Key\"].lower().endswith(\".txt\"))","    return keys","","def read_txt(bucket: str, key: str) -> str:","    \"\"\"Download and decode a text file.\"\"\"","    return s3.get_object(Bucket=bucket, Key=key)[\"Body\"].read().decode(\"utf-8\")","","def build_prompt(context: str, question: str) -> str:","    \"\"\"Gen-Z doctor persona → exactly three ≤20-word sentences.\"\"\"","    return f\"\"\"","You’re an upbeat Gen-Z doctor. Use ONLY the text in CONTEXT to explain the patient’s medical record in plain, friendly terms.","","OUTPUT RULES","1. Return valid JSON with a single key \"answer\".","2. \"answer\" must be EXACTLY three sentences (each ≤20 words):","   • Sentence 1 – quick vibe-check (“Yes, overall you’re healthy” / “No, chronic stuff to watch”).","   • Sentence 2 – cite one date/page/section for proof (“See 2024-03-02 blood test p.2”).","   • Sentence 3 – chill next step (“Book a GP chat this month”).","3. No other keys, markdown, or explanations.","4. Remove special characters, keep it casual and crystal-clear.","","CONTEXT","{context}","","QUESTION","{question}","","Return ONLY the JSON object described in rule 1.","\"\"\".strip()","","def query_llm(prompt: str) -> str:","    resp = client.chat.completions.create(","        model       = MODEL_ID,","        messages    = [{\"role\": \"user\", \"content\": prompt}],","        temperature = 0,","        top_p       = 0.9,","    )","    return resp.choices[0].message.content","","def extract_json(raw: str) -> str:","    \"\"\"","    Grab the first top-level {{...}} block; fall back to raw text.","    Prevents JSONDecodeError if model adds extra chatter.","    \"\"\"","    start = raw.find(\"{\")","    if start == -1:","        return raw.strip()","","    depth = 0","    for i, ch in enumerate(raw[start:]):","        if ch == \"{\":","            depth += 1","        elif ch == \"}\":","            depth -= 1","            if depth == 0:","                try:","                    return json.loads(raw[start:start + i + 1])[\"answer\"]","                except Exception:","                    break","    return raw.strip()","","# ── Lambda entry-point ───────────────────────────────────────────────","def lambda_handler(event, _ctx):","    # 1 — Parse request","    try:","        body = event.get(\"body\", event)","        if isinstance(body, str):","            body = json.loads(body)","        question = body[\"question\"]","    except Exception as exc:","        return {\"statusCode\": 400,","                \"body\": json.dumps(f\"Invalid request: {exc}\")}","","    # 2 — Aggregate context from S3","    context = \"\"","    for key in list_txt(PARSED_BUCKET):","        try:","            context += f\"\\n\\n--- {key} ---\\n\\n{read_txt(PARSED_BUCKET, key)}\"","        except Exception as exc:","            context += f\"\\n\\n--- Error reading {key}: {exc} ---\\n\\n\"","","    # 3 — Build prompt & query LLM","    prompt     = build_prompt(context, question)","    raw_reply  = query_llm(prompt)","    final_ans  = extract_json(raw_reply)","","    # Optional prompt preview for debugging","    if PROMPT_PREVIEW_LEN:","        print(\"PROMPT PREVIEW:\\n\",","              prompt[:PROMPT_PREVIEW_LEN] +","              (\"…\" if len(prompt) > PROMPT_PREVIEW_LEN else \"\"))","","    # 4 — HTTP response","    return {","        \"statusCode\": 200,","        \"headers\": {","            \"Access-Control-Allow-Origin\":  \"*\",","            \"Access-Control-Allow-Methods\": \"POST, OPTIONS\",","            \"Access-Control-Allow-Headers\": \"Content-Type\",","        },","        \"body\": json.dumps({","            \"question\": question,","            \"answer\":   final_ans","        })","    }",""]}],[{"start":{"row":4,"column":77},"end":{"row":4,"column":78},"action":"remove","lines":["s"],"id":133},{"start":{"row":4,"column":76},"end":{"row":4,"column":77},"action":"remove","lines":["d"]},{"start":{"row":4,"column":75},"end":{"row":4,"column":76},"action":"remove","lines":["r"]},{"start":{"row":4,"column":74},"end":{"row":4,"column":75},"action":"remove","lines":["o"]},{"start":{"row":4,"column":73},"end":{"row":4,"column":74},"action":"remove","lines":["c"]},{"start":{"row":4,"column":72},"end":{"row":4,"column":73},"action":"remove","lines":["e"]},{"start":{"row":4,"column":71},"end":{"row":4,"column":72},"action":"remove","lines":["r"]}],[{"start":{"row":4,"column":71},"end":{"row":4,"column":72},"action":"insert","lines":["h"],"id":134},{"start":{"row":4,"column":72},"end":{"row":4,"column":73},"action":"insert","lines":["i"]},{"start":{"row":4,"column":73},"end":{"row":4,"column":74},"action":"insert","lines":["s"]},{"start":{"row":4,"column":74},"end":{"row":4,"column":75},"action":"insert","lines":["t"]},{"start":{"row":4,"column":75},"end":{"row":4,"column":76},"action":"insert","lines":["o"]}],[{"start":{"row":4,"column":76},"end":{"row":4,"column":77},"action":"insert","lines":["r"],"id":135},{"start":{"row":4,"column":77},"end":{"row":4,"column":78},"action":"insert","lines":["y"]}],[{"start":{"row":38,"column":4},"end":{"row":41,"column":44},"action":"remove","lines":[" Sentence 1 – quick vibe-check (“Yes, overall you’re healthy” / “No, chronic stuff to watch”).","   • Sentence 2 – cite one date/page/section for proof (“See 2024-03-02 blood test p.2”).","   • Sentence 3 – chill next step (“Book a GP chat this month”).","3. No other keys, markdown, or explanations."],"id":136},{"start":{"row":38,"column":3},"end":{"row":38,"column":4},"action":"remove","lines":["•"]}],[{"start":{"row":38,"column":3},"end":{"row":38,"column":4},"action":"insert","lines":["a"],"id":137},{"start":{"row":38,"column":4},"end":{"row":38,"column":5},"action":"insert","lines":["n"]},{"start":{"row":38,"column":5},"end":{"row":38,"column":6},"action":"insert","lines":["s"]}],[{"start":{"row":38,"column":3},"end":{"row":38,"column":6},"action":"remove","lines":["ans"],"id":138},{"start":{"row":38,"column":3},"end":{"row":38,"column":9},"action":"insert","lines":["answer"]}],[{"start":{"row":38,"column":9},"end":{"row":38,"column":10},"action":"insert","lines":[" "],"id":139},{"start":{"row":38,"column":10},"end":{"row":38,"column":11},"action":"insert","lines":["i"]},{"start":{"row":38,"column":11},"end":{"row":38,"column":12},"action":"insert","lines":["n"]}],[{"start":{"row":38,"column":12},"end":{"row":38,"column":13},"action":"insert","lines":[" "],"id":140}],[{"start":{"row":38,"column":13},"end":{"row":38,"column":14},"action":"insert","lines":["g"],"id":141},{"start":{"row":38,"column":14},"end":{"row":38,"column":15},"action":"insert","lines":["e"]},{"start":{"row":38,"column":15},"end":{"row":38,"column":16},"action":"insert","lines":["n"]},{"start":{"row":38,"column":16},"end":{"row":38,"column":17},"action":"insert","lines":["e"]},{"start":{"row":38,"column":17},"end":{"row":38,"column":18},"action":"insert","lines":["r"]},{"start":{"row":38,"column":18},"end":{"row":38,"column":19},"action":"insert","lines":["a"]},{"start":{"row":38,"column":19},"end":{"row":38,"column":20},"action":"insert","lines":["l"]}],[{"start":{"row":38,"column":20},"end":{"row":38,"column":21},"action":"insert","lines":[" "],"id":142}],[{"start":{"row":38,"column":20},"end":{"row":38,"column":21},"action":"remove","lines":[" "],"id":143}],[{"start":{"row":38,"column":20},"end":{"row":38,"column":21},"action":"insert","lines":[" "],"id":144},{"start":{"row":38,"column":21},"end":{"row":38,"column":22},"action":"insert","lines":["a"]},{"start":{"row":38,"column":22},"end":{"row":38,"column":23},"action":"insert","lines":["n"]},{"start":{"row":38,"column":23},"end":{"row":38,"column":24},"action":"insert","lines":["d"]}],[{"start":{"row":38,"column":24},"end":{"row":38,"column":25},"action":"insert","lines":[" "],"id":145}],[{"start":{"row":38,"column":25},"end":{"row":38,"column":26},"action":"insert","lines":["r"],"id":146},{"start":{"row":38,"column":26},"end":{"row":38,"column":27},"action":"insert","lines":["e"]},{"start":{"row":38,"column":27},"end":{"row":38,"column":28},"action":"insert","lines":["f"]},{"start":{"row":38,"column":28},"end":{"row":38,"column":29},"action":"insert","lines":["e"]},{"start":{"row":38,"column":29},"end":{"row":38,"column":30},"action":"insert","lines":["r"]}],[{"start":{"row":38,"column":30},"end":{"row":38,"column":31},"action":"insert","lines":[" "],"id":147},{"start":{"row":38,"column":31},"end":{"row":38,"column":32},"action":"insert","lines":["t"]},{"start":{"row":38,"column":32},"end":{"row":38,"column":33},"action":"insert","lines":["o"]}],[{"start":{"row":38,"column":33},"end":{"row":38,"column":34},"action":"insert","lines":[" "],"id":148},{"start":{"row":38,"column":34},"end":{"row":38,"column":35},"action":"insert","lines":["d"]},{"start":{"row":38,"column":35},"end":{"row":38,"column":36},"action":"insert","lines":["a"]},{"start":{"row":38,"column":36},"end":{"row":38,"column":37},"action":"insert","lines":["t"]},{"start":{"row":38,"column":37},"end":{"row":38,"column":38},"action":"insert","lines":["e"]},{"start":{"row":38,"column":38},"end":{"row":38,"column":39},"action":"insert","lines":["s"]}],[{"start":{"row":38,"column":39},"end":{"row":38,"column":40},"action":"insert","lines":[" "],"id":149},{"start":{"row":38,"column":40},"end":{"row":38,"column":41},"action":"insert","lines":["o"]},{"start":{"row":38,"column":41},"end":{"row":38,"column":42},"action":"insert","lines":["f"]}],[{"start":{"row":38,"column":42},"end":{"row":38,"column":43},"action":"insert","lines":[" "],"id":150},{"start":{"row":38,"column":43},"end":{"row":38,"column":44},"action":"insert","lines":["t"]},{"start":{"row":38,"column":44},"end":{"row":38,"column":45},"action":"insert","lines":["h"]},{"start":{"row":38,"column":45},"end":{"row":38,"column":46},"action":"insert","lines":["e"]}],[{"start":{"row":38,"column":46},"end":{"row":38,"column":47},"action":"insert","lines":[" "],"id":151},{"start":{"row":38,"column":47},"end":{"row":38,"column":48},"action":"insert","lines":["v"]},{"start":{"row":38,"column":48},"end":{"row":38,"column":49},"action":"insert","lines":["i"]},{"start":{"row":38,"column":49},"end":{"row":38,"column":50},"action":"insert","lines":["s"]},{"start":{"row":38,"column":50},"end":{"row":38,"column":51},"action":"insert","lines":["i"]},{"start":{"row":38,"column":51},"end":{"row":38,"column":52},"action":"insert","lines":["t"]}],[{"start":{"row":38,"column":52},"end":{"row":38,"column":53},"action":"insert","lines":[" "],"id":152},{"start":{"row":38,"column":53},"end":{"row":38,"column":54},"action":"insert","lines":["i"]},{"start":{"row":38,"column":54},"end":{"row":38,"column":55},"action":"insert","lines":["f"]}],[{"start":{"row":38,"column":55},"end":{"row":38,"column":56},"action":"insert","lines":[" "],"id":153},{"start":{"row":38,"column":56},"end":{"row":38,"column":57},"action":"insert","lines":["r"]},{"start":{"row":38,"column":57},"end":{"row":38,"column":58},"action":"insert","lines":["e"]},{"start":{"row":38,"column":58},"end":{"row":38,"column":59},"action":"insert","lines":["l"]},{"start":{"row":38,"column":59},"end":{"row":38,"column":60},"action":"insert","lines":["e"]},{"start":{"row":38,"column":60},"end":{"row":38,"column":61},"action":"insert","lines":["v"]},{"start":{"row":38,"column":61},"end":{"row":38,"column":62},"action":"insert","lines":["a"]},{"start":{"row":38,"column":62},"end":{"row":38,"column":63},"action":"insert","lines":["n"]},{"start":{"row":38,"column":63},"end":{"row":38,"column":64},"action":"insert","lines":["t"]}],[{"start":{"row":38,"column":64},"end":{"row":38,"column":65},"action":"insert","lines":[" "],"id":154}],[{"start":{"row":38,"column":64},"end":{"row":38,"column":65},"action":"remove","lines":[" "],"id":155}]]},"ace":{"folds":[],"scrolltop":0,"scrollleft":0,"selection":{"start":{"row":38,"column":64},"end":{"row":38,"column":64},"isBackwards":false},"options":{"guessTabSize":true,"useWrapMode":false,"wrapToView":true},"firstLineState":0},"timestamp":1750266527287,"hash":"a83f9eedff66247efe9972fb51e0a9dbe8058ddb"}